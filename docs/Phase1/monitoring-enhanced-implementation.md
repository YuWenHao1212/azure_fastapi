# å¢å¼·ç‰ˆç›£æ§å¯¦ä½œæŒ‡å—

## 1. OpenAI Client Token è¿½è¹¤å¯¦ä½œ

### ä¿®æ”¹ `src/services/openai_client.py`

åœ¨ `_chat_completion_non_stream` æ–¹æ³•çš„ç¬¬ 153 è¡Œå¾Œæ·»åŠ ï¼š

```python
# åœ¨å–å¾— result å¾Œç«‹å³è¿½è¹¤ token ä½¿ç”¨
from src.core.monitoring_service import monitoring_service

# æå– token ä½¿ç”¨è³‡è¨Š
usage = result.get('usage', {})
monitoring_service.track_event(
    "OpenAITokenUsage",
    {
        "deployment": self.deployment_id,
        "operation": "chat_completion",
        "prompt_tokens": usage.get('prompt_tokens', 0),
        "completion_tokens": usage.get('completion_tokens', 0),
        "total_tokens": usage.get('total_tokens', 0),
        "model": result.get("model", self.deployment_id),
        "finish_reason": result.get('choices', [{}])[0].get('finish_reason', 'unknown'),
        "temperature": payload.get('temperature', 0.7),
        "max_tokens": payload.get('max_tokens', 1000)
    }
)
```

## 2. Gap Analysis Service å¢å¼·ç›£æ§

### ä¿®æ”¹ `src/services/gap_analysis.py`

åœ¨ç¬¬ 16 è¡Œå¾Œæ·»åŠ  mixin importï¼š
```python
from src.services.token_tracking_mixin import TokenTrackingMixin
```

ä¿®æ”¹ class å®šç¾©ï¼ˆç¬¬ 160 è¡Œï¼‰ï¼š
```python
class GapAnalysisService(TokenTrackingMixin):
```

åœ¨ `analyze_gap` æ–¹æ³•ä¸­è¿½è¹¤è©³ç´°æŒ‡æ¨™ï¼ˆç¬¬ 235 è¡Œå¾Œï¼‰ï¼š

```python
# æå– response content å¾Œ
llm_response = response['choices'][0]['message']['content']

# è¿½è¹¤ token ä½¿ç”¨å’Œæ™‚é–“
llm_time = time.time() - llm_start_time  # éœ€è¦åœ¨èª¿ç”¨å‰è¨˜éŒ„ llm_start_time
token_info = self.track_openai_usage(
    response,
    operation="gap_analysis",
    additional_properties={
        "language": language,
        "processing_time_ms": round(llm_time * 1000, 2),
        "prompt_length": len(system_prompt) + len(user_prompt),
        "response_length": len(llm_response)
    }
)

# è¨˜éŒ„è©³ç´°çš„ gap analysis å®Œæˆäº‹ä»¶
monitoring_service.track_event(
    "GapAnalysisCompleted",
    {
        "language": language,
        "prompt_tokens": token_info["prompt_tokens"],
        "completion_tokens": token_info["completion_tokens"],
        "total_tokens": token_info["total_tokens"],
        "processing_time_ms": round(llm_time * 1000, 2),
        "estimated_cost_usd": self.estimate_token_cost(
            token_info["prompt_tokens"],
            token_info["completion_tokens"]
        ),
        "skill_queries_count": len(parsed_response.get('skill_queries', [])),
        "response_sections": {
            "strengths": len(parsed_response.get('strengths', [])),
            "gaps": len(parsed_response.get('gaps', [])),
            "improvements": len(parsed_response.get('improvements', []))
        }
    }
)
```

## 3. Index Calculation Service å¢å¼·ç›£æ§

### ä¿®æ”¹ `src/services/index_calculation.py`

åœ¨è¨ˆç®— embeddings æ™‚æ·»åŠ æ™‚é–“è¿½è¹¤ï¼š

```python
# åœ¨ calculate_similarity æ–¹æ³•ä¸­
embedding_start = time.time()

# å‰µå»º embeddings
resume_embedding = await self.embedding_client.create_embeddings([resume_text])
jd_embedding = await self.embedding_client.create_embeddings([jd_text])

embedding_time = time.time() - embedding_start

# è¿½è¹¤ embedding æ•ˆèƒ½
monitoring_service.track_event(
    "EmbeddingPerformance",
    {
        "operation": "index_calculation",
        "text_lengths": {
            "resume": len(resume_text),
            "job_description": len(jd_text)
        },
        "processing_time_ms": round(embedding_time * 1000, 2),
        "embeddings_count": 2,
        "estimated_tokens": (len(resume_text) + len(jd_text)) // 4  # ç²—ç•¥ä¼°ç®—
    }
)
```

## 4. API ç«¯é»å®Œæ•´æŒ‡æ¨™è¿½è¹¤

### ä¿®æ”¹ `src/api/v1/index_cal_and_gap_analysis.py`

åœ¨ç¬¬ 147 è¡Œçš„ track_event èª¿ç”¨ä¸­æ·»åŠ æ›´å¤šæŒ‡æ¨™ï¼š

```python
# æ”¶é›†å„éšæ®µæ™‚é–“
index_time = index_end_time - start_time  # éœ€è¦è¨˜éŒ„ index_end_time
gap_time = gap_end_time - index_end_time  # éœ€è¦è¨˜éŒ„ gap_end_time
total_time = time.time() - start_time

monitoring_service.track_event(
    "IndexCalAndGapAnalysisCompleted",
    {
        # ç¾æœ‰æŒ‡æ¨™
        "raw_similarity": index_result["raw_similarity_percentage"],
        "transformed_similarity": index_result["similarity_percentage"],
        "keyword_coverage": keyword_coverage["coverage_percentage"],
        "language": request.language,
        "skills_identified": len(gap_result.get("SkillSearchQueries", [])),
        
        # æ–°å¢æ™‚é–“æŒ‡æ¨™
        "total_time_ms": round(total_time * 1000, 2),
        "index_calc_time_ms": round(index_time * 1000, 2),
        "gap_analysis_time_ms": round(gap_time * 1000, 2),
        
        # æ–°å¢è³‡æ–™å¤§å°æŒ‡æ¨™
        "resume_length": len(request.resume),
        "jd_length": len(request.job_description),
        "keywords_count": len(keywords_list),
        
        # æ–°å¢çµæœæŒ‡æ¨™
        "matched_keywords_count": len(keyword_coverage["covered_keywords"]),
        "missed_keywords_count": len(keyword_coverage["missed_keywords"])
    }
)
```

## 5. å»ºç«‹ Azure Monitor Workbook

### åŸºæœ¬ Dashboard é…ç½®

```json
{
  "version": "Notebook/1.0",
  "items": [
    {
      "type": "text",
      "content": {
        "json": "# Index Calculation & Gap Analysis Dashboard"
      }
    },
    {
      "type": "query",
      "name": "API Success Rate",
      "query": "customEvents | where timestamp > ago(1h) | where name in ('IndexCalculationCompleted', 'IndexCalAndGapAnalysisCompleted') | summarize Success = count(), Total = count() by bin(timestamp, 5m) | extend SuccessRate = 100.0 * Success / Total | render timechart"
    },
    {
      "type": "query", 
      "name": "Token Usage Trend",
      "query": "customEvents | where timestamp > ago(1h) | where name == 'OpenAITokenUsage' | summarize TotalTokens = sum(toint(customDimensions.total_tokens)) by bin(timestamp, 5m) | render timechart"
    }
  ]
}
```

## 6. æˆæœ¬ç›£æ§æŸ¥è©¢

```kusto
// æ¯å°æ™‚ API ä½¿ç”¨æˆæœ¬
customEvents
| where timestamp > ago(24h)
| where name == "OpenAITokenUsage"
| extend 
    PromptTokens = toint(customDimensions.prompt_tokens),
    CompletionTokens = toint(customDimensions.completion_tokens),
    Operation = tostring(customDimensions.operation)
| summarize 
    TotalPromptTokens = sum(PromptTokens),
    TotalCompletionTokens = sum(CompletionTokens)
  by bin(timestamp, 1h), Operation
| extend 
    PromptCost = TotalPromptTokens * 0.01 / 1000,
    CompletionCost = TotalCompletionTokens * 0.03 / 1000,
    TotalCost = PromptCost + CompletionCost
| project timestamp, Operation, TotalCost, TotalPromptTokens, TotalCompletionTokens
| order by timestamp desc
```

## 7. æ•ˆèƒ½åˆ†ææŸ¥è©¢

```kusto
// API ç«¯é»æ•ˆèƒ½åˆ†è§£
customEvents
| where timestamp > ago(1h)
| where name == "IndexCalAndGapAnalysisCompleted"
| extend 
    TotalTime = todouble(customDimensions.total_time_ms),
    IndexTime = todouble(customDimensions.index_calc_time_ms),
    GapTime = todouble(customDimensions.gap_analysis_time_ms)
| summarize 
    avg(TotalTime), percentiles(TotalTime, 50, 90, 95),
    avg(IndexTime), percentiles(IndexTime, 50, 90, 95),
    avg(GapTime), percentiles(GapTime, 50, 90, 95),
    count()
| extend 
    IndexTimeRatio = avg_IndexTime / avg_TotalTime * 100,
    GapTimeRatio = avg_GapTime / avg_TotalTime * 100
```

## 8. ç•°å¸¸æª¢æ¸¬å‘Šè­¦

### è¨­ç½® Application Insights Alert Rules

1. **é«˜éŒ¯èª¤ç‡å‘Šè­¦**
   - æ¢ä»¶: éŒ¯èª¤äº‹ä»¶æ•¸ > 5 in 5 minutes
   - æŸ¥è©¢: `customEvents | where name contains "Error" | count`

2. **Token ä½¿ç”¨ç•°å¸¸å‘Šè­¦**
   - æ¢ä»¶: å¹³å‡ token ä½¿ç”¨ > 3000 per request
   - æŸ¥è©¢: `customEvents | where name == "OpenAITokenUsage" | summarize avg(toint(customDimensions.total_tokens))`

3. **å›æ‡‰æ™‚é–“éé•·å‘Šè­¦**
   - æ¢ä»¶: P95 è™•ç†æ™‚é–“ > 10 ç§’
   - æŸ¥è©¢: `customEvents | where name contains "Completed" | summarize percentile(todouble(customDimensions.processing_time_ms), 95)`

## å¯¦ä½œå„ªå…ˆé †åº

1. **ç«‹å³å¯¦ä½œ** (Phase 1)
   - âœ… OpenAI Client token è¿½è¹¤
   - âœ… API ç«¯é»åŸºæœ¬ç›£æ§
   - âœ… éŒ¯èª¤äº‹ä»¶è¿½è¹¤

2. **çŸ­æœŸå¯¦ä½œ** (Phase 2)
   - ğŸ“Š Token æˆæœ¬è¨ˆç®—
   - ğŸ“Š è©³ç´°æ™‚é–“åˆ†è§£
   - ğŸ“Š Azure Workbook è¨­ç½®

3. **é•·æœŸå„ªåŒ–** (Phase 3)
   - ğŸ”§ è‡ªå‹•å‘Šè­¦è¨­ç½®
   - ğŸ”§ æˆæœ¬å„ªåŒ–å»ºè­°
   - ğŸ”§ æ•ˆèƒ½ç“¶é ¸åˆ†æ