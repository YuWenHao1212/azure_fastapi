# 關鍵字提取 API 效能優化提案

**文檔編號**: PERF_KEYWORDS_EXTRACTION_20250726  
**撰寫日期**: 2025-07-26  
**作者**: Claude Code  
**狀態**: 草稿  
**GitHub Issue**: #[待建立]

## 摘要

本文檔分析 `/api/v1/extract-jd-keywords` API 的效能瓶頸，並提出優化方案。目標是將 P95 回應時間從目前的狀態優化至 2.5 秒以內。

## 當前狀況

### API 端點資訊
- **端點**: `POST /api/v1/extract-jd-keywords`
- **功能**: 從職位描述中提取關鍵字
- **LLM 模型**: Azure OpenAI GPT-4o-2 (deployment: gpt-4o-2)
- **目標回應時間**: < 2.5 秒
- **支援語言**: 繁體中文、英文

### 效能測試計劃

將使用以下測試案例進行基準測試：

#### 測試資料集
1. **英文 JD** (500-800 字)
   - Software Engineer
   - Data Scientist
   - Product Manager

2. **繁體中文 JD** (500-800 字)
   - 軟體工程師
   - 資料科學家
   - 產品經理

#### 測試維度
- 不同長度的 JD (500字、650字、800字)
- 不同語言 (英文、繁體中文)
- 不同時段 (避免網路擁塞影響)
- 連續請求 vs 單次請求

## 效能分析方法

### 1. Time Budget 分析
```
總回應時間 = 網路延遲 + API 處理時間
API 處理時間 = 
  - 請求驗證
  - Prompt 準備
  - LLM 呼叫時間
  - 回應解析
  - 資料格式化
```

### 2. 關鍵指標
- 平均回應時間
- P95 回應時間
- P99 回應時間
- 錯誤率
- Token 使用量

## 優化策略假設

### 1. LLM 區域優化
- **問題**: 目前使用 Sweden Central 區域的 Azure OpenAI
- **方案**: 評估切換到 East Asia 區域的可行性
- **預期改善**: 減少 100-200ms 網路延遲

### 2. Prompt 工程優化
- **問題**: 當前 prompt 可能過於複雜
- **方案**: 
  - 簡化 prompt 結構
  - 減少範例數量
  - 使用更精確的指令
- **預期改善**: 減少 10-20% token 使用量

### 3. 關鍵字數量修正
- **問題**: API 應該返回 16 個關鍵字（預設值），而非 5 個
- **方案**: 確保請求正確設置 max_keywords 參數
- **預期改善**: 提供更豐富的關鍵字集合

### 4. 模型選擇優化
- **問題**: GPT-4o-2 可能對關鍵字提取任務過度強大
- **方案**: 評估使用 GPT-4o-mini 的可行性（不考慮 GPT-3.5-turbo）
- **預期改善**: 回應時間減少 30-50%，同時維持提取品質

### 5. 並行處理優化
- **問題**: 某些處理步驟可能是序列執行
- **方案**: 識別可並行化的部分（已實作 Round1/Round2 並行）
- **預期改善**: 整體處理時間減少 10-15%

### 6. 快取策略
- **問題**: 相似 JD 重複處理
- **方案**: 實作智慧快取機制（已啟用 60 分鐘 TTL）
- **預期改善**: 命中率 20% 的情況下，平均回應時間減少 15%

## 測試腳本

### 簡單效能測試
```bash
# 基本效能測試（5次重複）
python temp/tests/scripts/test_keywords_performance_20250726.py
```

### 詳細效能分析
```bash
# 詳細時間分解分析（英文/中文各3個不同JD，每個2次）
python temp/tests/scripts/test_keywords_detailed_performance_20250726.py
```

詳細分析腳本會追蹤：
- 請求準備時間
- 網路請求時間（含網路延遲）
- 伺服器處理時間分解：
  - 請求驗證
  - 語言檢測
  - 關鍵字提取（LLM 呼叫）
- 回應解析時間

## 效能分析重點

基於詳細的時間分解，我們可以準確識別瓶頸：
1. **網路延遲**：Sweden Central → API 的往返時間
2. **LLM 處理時間**：GPT-4o-2 模型的推理時間
3. **其他處理開銷**：驗證、語言檢測等

## 下一步行動

1. **執行基準測試** - 獲取當前效能數據
2. **分析瓶頸** - 識別最耗時的部分
3. **實施優化** - 按優先順序執行優化方案
4. **驗證結果** - 確認達到目標

## 成功標準

- [ ] P95 回應時間 < 2.5 秒
- [ ] 錯誤率 < 0.1%
- [ ] 支援每秒 10 個並發請求
- [ ] Token 成本降低 20%

## 風險評估

1. **模型降級風險**: 使用較小模型可能影響提取品質
2. **區域切換風險**: 需要重新申請配額
3. **快取一致性**: 需要設計合理的快取失效策略

## 相關文檔

- [API_REFERENCE.md](/docs/API_REFERENCE.md)
- [ARCHITECTURE.md](/docs/ARCHITECTURE.md)
- [Phase 1 關鍵字提取設計](/docs/Phase1/published/DESIGN_KEYWORD_EXTRACTION_20250701.md)