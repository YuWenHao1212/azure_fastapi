# 最終 top_p 參數分析報告

## 完整測試結果匯總

所有測試使用相同配置：
- **temperature**: 0.0
- **seed**: 42
- **測試對象**: TSMC Sr. HR Data Analyst JD (2591字)
- **測試次數**: 各50次

## 結果排名（從最佳到最差）

| 排名 | top_p | 唯一組合 | 最常見組合 | 穩定關鍵字 | 標準差 | 改進率 |
|------|-------|----------|------------|------------|--------|--------|
| 🥇 | **0.1** | **32** | 8% (4次) | 6個 | 0.83 | **↓17.9%** |
| 🥈 | 0.05 | 34 | 10% (5次) | 7個 | 1.01 | ↓12.8% |
| 🥉 | 0.2 | 36 | 6% (3次) | 6個 | 0.64 | ↓7.7% |
| ❌ | 原始 | 39 | 6% (3次) | - | - | Baseline |

## 關鍵發現

### 1. **top_p=0.1 是最優值**
- 提供最少的唯一組合（32個）
- 改進率最高（17.9%）
- 標準差適中（0.83），表示分佈合理集中

### 2. **top_p 與一致性的關係呈 U 型曲線**
```
一致性
  ↑
  │     最佳點
  │       ↓
  │    ╱───╲
  │   ╱     ╲
  │  ╱       ╲
  └────────────→ top_p
  0.05  0.1  0.2
```

### 3. **過低或過高都會降低一致性**
- **top_p=0.05**：過度限制，雖有更多穩定關鍵字，但整體變異反而增加
- **top_p=0.2**：限制不足，回到接近原始狀態的變異性

## 詳細分析

### top_p=0.05
- ✅ 優點：最多穩定關鍵字（7個）、最高單一組合頻率（10%）
- ❌ 缺點：標準差最高（1.01）、整體一致性不如0.1

### top_p=0.1
- ✅ 優點：最佳整體一致性、合理的處理速度
- ✅ 優點：標準差適中、改進率最高
- ➖ 中性：穩定關鍵字數量中等（6個）

### top_p=0.2
- ❌ 缺點：一致性最差（36個組合）
- ❌ 缺點：改進率最低（僅7.7%）
- ✅ 優點：標準差最低（0.64），但這反映的是分散而非集中

## 技術解釋

**為什麼 top_p=0.1 最優？**

1. **平衡點**：在限制性和靈活性之間找到最佳平衡
2. **與 temperature=0.0 的協同**：兩者配合產生最穩定的輸出
3. **模型特性**：GPT-4o-2 在這個參數下表現最穩定

**為什麼極端值表現不佳？**

- **top_p=0.05**：選擇空間過小，模型在極少選項中「掙扎」
- **top_p=0.2**：選擇空間過大，無法有效約束輸出

## 最終建議

### 🎯 **維持 top_p=0.1 配置**

```python
temperature=0.0   # 零溫度確保確定性
top_p=0.1        # 最優的核心採樣範圍
seed=42          # 固定種子（效果有限但無害）
```

這個配置提供：
- **最佳一致性**：32個唯一組合（改進17.9%）
- **穩定表現**：6個完全穩定的關鍵字
- **合理速度**：平均2.10秒處理時間

## 結論

經過系統性測試 top_p 的三個值（0.05、0.1、0.2），確認 **top_p=0.1** 是最優選擇。這個值在限制性和靈活性之間達到最佳平衡，為複雜長文本的關鍵字提取提供最高的一致性。