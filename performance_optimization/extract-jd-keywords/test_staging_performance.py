#!/usr/bin/env python3
"""
Staging ç’°å¢ƒæ•ˆèƒ½è¿½è¹¤æ¸¬è©¦è…³æœ¬
æ¸¬è©¦æ–°å¢çš„è©³ç´°æ•ˆèƒ½è¿½è¹¤åŠŸèƒ½
"""
import asyncio
import json
import time
import os
from datetime import datetime
from typing import Dict, List, Any
import httpx
import statistics
from collections import defaultdict
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# æ¸¬è©¦é…ç½®
# æ³¨æ„ï¼šstaging slot çš„ URL æ ¼å¼
STAGING_URL = "https://airesumeadvisor-fastapi-premium-staging.azurewebsites.net"
# ä½¿ç”¨ Premium Staging Host Key
FUNCTION_KEY = (
    os.getenv("PREMIUM_STAGING_HOST_KEY") or  # å„ªå…ˆä½¿ç”¨ staging key
    os.getenv("STAGING_FUNCTION_KEY") or 
    os.getenv("FUNCTION_KEY_STAGING")
)

# æ¸¬è©¦æ¡ˆä¾‹
TEST_CASES = [
    {
        "name": "English Short JD",
        "language": "en",
        "job_description": """
        We are looking for a talented Full Stack Developer to join our growing team.
        The ideal candidate should have strong experience with React.js, Node.js, and 
        cloud services like AWS. Experience with Docker and Kubernetes is a plus.
        Strong problem-solving skills and ability to work in an agile environment.
        """.strip()
    },
    {
        "name": "English Long JD",
        "language": "en", 
        "job_description": """
        We are seeking an experienced Senior Software Engineer to lead our backend development initiatives.
        This is an exciting opportunity to work on cutting-edge technology and make a significant impact.
        
        Key Responsibilities:
        - Design and implement scalable microservices architecture using Python and Go
        - Lead technical discussions and mentor junior developers
        - Collaborate with product managers to define technical requirements
        - Optimize database performance with PostgreSQL and Redis
        - Implement CI/CD pipelines using Jenkins and GitLab CI
        - Ensure code quality through comprehensive testing and code reviews
        
        Required Qualifications:
        - Bachelor's degree in Computer Science or related field
        - 5+ years of experience in backend development
        - Strong proficiency in Python, with knowledge of Django or FastAPI
        - Experience with containerization using Docker and orchestration with Kubernetes
        - Solid understanding of RESTful API design principles
        - Experience with message queuing systems like RabbitMQ or Kafka
        - Strong knowledge of SQL and NoSQL databases
        - Experience with AWS services (EC2, S3, RDS, Lambda)
        
        Nice to Have:
        - Experience with Go programming language
        - Knowledge of GraphQL
        - Experience with monitoring tools like Prometheus and Grafana
        - Understanding of security best practices
        - Contributions to open source projects
        
        What We Offer:
        - Competitive salary and equity package
        - Flexible working hours and remote work options
        - Health insurance and wellness programs
        - Professional development budget
        - Collaborative and inclusive work environment
        """.strip()
    },
    {
        "name": "Chinese Short JD",
        "language": "zh-TW",
        "job_description": """
        æˆ‘å€‘æ­£åœ¨å°‹æ‰¾ä¸€ä½è³‡æ·±å‰ç«¯å·¥ç¨‹å¸«ï¼Œéœ€è¦ç²¾é€š Reactã€Vue.js å’Œ TypeScriptã€‚
        å…·å‚™éŸ¿æ‡‰å¼ç¶²é è¨­è¨ˆç¶“é©—ï¼Œç†Ÿæ‚‰ Git ç‰ˆæœ¬æ§åˆ¶å’Œæ•æ·é–‹ç™¼æµç¨‹ã€‚
        æœ‰å¤§å‹å°ˆæ¡ˆç¶“é©—è€…å„ªå…ˆè€ƒæ…®ã€‚
        """.strip()
    },
    {
        "name": "Chinese Long JD",
        "language": "zh-TW",
        "job_description": """
        ã€è·ä½åç¨±ã€‘è³‡æ·±å…¨ç«¯å·¥ç¨‹å¸« Senior Full Stack Engineer

        ã€å·¥ä½œå…§å®¹ã€‘
        1. è² è²¬å…¬å¸æ ¸å¿ƒç”¢å“çš„å‰å¾Œç«¯é–‹ç™¼èˆ‡ç¶­è­·
        2. åƒèˆ‡ç³»çµ±æ¶æ§‹è¨­è¨ˆï¼Œç¢ºä¿ç³»çµ±çš„å¯æ“´å±•æ€§å’Œé«˜å¯ç”¨æ€§
        3. èˆ‡ç”¢å“ç¶“ç†ã€è¨­è¨ˆå¸«å¯†åˆ‡åˆä½œï¼Œå°‡éœ€æ±‚è½‰åŒ–ç‚ºæŠ€è¡“å¯¦ç¾
        4. å„ªåŒ–ç¾æœ‰ç¨‹å¼ç¢¼ï¼Œæå‡ç³»çµ±æ•ˆèƒ½å’Œä½¿ç”¨è€…é«”é©—
        5. æ’°å¯«æŠ€è¡“æ–‡æª”ï¼Œåˆ†äº«æœ€ä½³å¯¦è¸
        6. æŒ‡å°åˆç´šå·¥ç¨‹å¸«ï¼Œå”åŠ©åœ˜éšŠæˆé•·

        ã€è·ä½è¦æ±‚ã€‘
        å¿…å‚™æŠ€èƒ½ï¼š
        - 5å¹´ä»¥ä¸Šå…¨ç«¯é–‹ç™¼ç¶“é©—
        - ç²¾é€š JavaScript/TypeScriptï¼Œç†Ÿç·´ä½¿ç”¨ React.js æˆ– Vue.js
        - ç†Ÿæ‚‰ Node.js å¾Œç«¯é–‹ç™¼ï¼Œæœ‰ Express.js æˆ– Nest.js ç¶“é©—
        - æŒæ¡é—œè¯å¼è³‡æ–™åº«ï¼ˆMySQL/PostgreSQLï¼‰å’Œ NoSQLï¼ˆMongoDB/Redisï¼‰
        - ç†Ÿæ‚‰ RESTful API è¨­è¨ˆåŸå‰‡ï¼Œæœ‰ GraphQL ç¶“é©—æ›´ä½³
        - äº†è§£å¾®æœå‹™æ¶æ§‹å’Œå®¹å™¨åŒ–æŠ€è¡“ï¼ˆDocker/Kubernetesï¼‰
        - ç†Ÿæ‚‰ Git ç‰ˆæœ¬æ§åˆ¶å’Œ CI/CD æµç¨‹

        åŠ åˆ†é …ç›®ï¼š
        - æœ‰é›²ç«¯æœå‹™ç¶“é©—ï¼ˆAWS/GCP/Azureï¼‰
        - ç†Ÿæ‚‰ Python æˆ– Go èªè¨€
        - æœ‰å¤§æµé‡ç¶²ç«™å„ªåŒ–ç¶“é©—
        - åƒèˆ‡éé–‹æºå°ˆæ¡ˆ
        - å…·å‚™ DevOps ç›¸é—œç¶“é©—
        - æœ‰é‡‘èç§‘æŠ€æˆ–é›»å•†é ˜åŸŸç¶“é©—

        ã€æˆ‘å€‘æä¾›ã€‘
        - å…·ç«¶çˆ­åŠ›çš„è–ªè³‡å¾…é‡
        - å½ˆæ€§å·¥ä½œæ™‚é–“å’Œé ç«¯å·¥ä½œé¸é …
        - å®Œå–„çš„å“¡å·¥åŸ¹è¨“è¨ˆç•«
        - å®šæœŸæŠ€è¡“åˆ†äº«æœƒå’Œè®€æ›¸æœƒ
        - ç¾ä»£åŒ–çš„è¾¦å…¬ç’°å¢ƒå’Œè¨­å‚™
        """.strip()
    }
]

async def test_single_request(
    client: httpx.AsyncClient,
    test_case: Dict[str, Any],
    iteration: int
) -> Dict[str, Any]:
    """åŸ·è¡Œå–®æ¬¡æ¸¬è©¦è«‹æ±‚"""
    
    url = f"{STAGING_URL}/api/v1/extract-jd-keywords?code={FUNCTION_KEY}"
    
    payload = {
        "job_description": test_case["job_description"],
        "language": test_case["language"],
        "max_keywords": 15,
        "prompt_version": "latest"
    }
    
    start_time = time.time()
    
    try:
        response = await client.post(url, json=payload, timeout=30.0)
        end_time = time.time()
        
        total_time_ms = (end_time - start_time) * 1000
        
        if response.status_code == 200:
            data = response.json()
            
            if data.get("success"):
                result = data["data"]
                
                # æå–è©³ç´°çš„æ™‚é–“æŒ‡æ¨™
                timing_breakdown = result.get("timing_breakdown", {})
                
                return {
                    "iteration": iteration,
                    "test_case": test_case["name"],
                    "language": test_case["language"],
                    "jd_length": len(test_case["job_description"]),
                    "status": "success",
                    "total_time_ms": total_time_ms,
                    "api_processing_ms": result.get("processing_time_ms", 0),
                    "service_init_ms": timing_breakdown.get("service_init_ms", 0),
                    "validation_ms": timing_breakdown.get("validation_ms", 0),
                    "extraction_ms": timing_breakdown.get("keyword_extraction_ms", 0),
                    "language_detection_ms": result.get("language_detection_time_ms", 0),
                    "cache_hit": result.get("cache_hit", False),
                    "keyword_count": result.get("keyword_count", 0),
                    "detected_language": result.get("detected_language", ""),
                    "extraction_method": result.get("extraction_method", ""),
                    "confidence_score": result.get("confidence_score", 0)
                }
            else:
                return {
                    "iteration": iteration,
                    "test_case": test_case["name"],
                    "status": "api_error",
                    "error": data.get("error", {}).get("message", "Unknown error"),
                    "total_time_ms": total_time_ms
                }
        else:
            # å˜—è©¦ç²å–éŒ¯èª¤è¨Šæ¯
            error_detail = ""
            try:
                error_data = response.json()
                error_detail = error_data.get("detail", response.text[:200])
            except:
                error_detail = response.text[:200]
            
            return {
                "iteration": iteration,
                "test_case": test_case["name"],
                "status": "http_error",
                "status_code": response.status_code,
                "error_detail": error_detail,
                "total_time_ms": total_time_ms
            }
            
    except Exception as e:
        return {
            "iteration": iteration,
            "test_case": test_case["name"],
            "status": "exception",
            "error": str(e),
            "total_time_ms": (time.time() - start_time) * 1000
        }

async def run_performance_tests(iterations: int = 5):
    """åŸ·è¡Œæ•ˆèƒ½æ¸¬è©¦"""
    
    print(f"\nğŸš€ é–‹å§‹ Staging ç’°å¢ƒæ•ˆèƒ½è¿½è¹¤æ¸¬è©¦")
    print(f"ğŸ“ ç›®æ¨™: {STAGING_URL}")
    print(f"ğŸ”„ æ¯å€‹æ¸¬è©¦æ¡ˆä¾‹åŸ·è¡Œ {iterations} æ¬¡\n")
    
    if not FUNCTION_KEY:
        print("âš ï¸  è­¦å‘Š: æ‰¾ä¸åˆ° Function Key!")
        print("   è«‹ç¢ºèª .env æª”æ¡ˆä¸­æœ‰è¨­å®šä»¥ä¸‹ä»»ä¸€ç’°å¢ƒè®Šæ•¸:")
        print("   - PREMIUM_STAGING_HOST_KEY (æ¨è–¦)")
        print("   - STAGING_FUNCTION_KEY")
        print("   - FUNCTION_KEY_STAGING")
        return
    
    print(f"âœ… ä½¿ç”¨ Function Key: {FUNCTION_KEY[:10]}...")
    
    async with httpx.AsyncClient() as client:
        # é ç†±è«‹æ±‚
        print("ğŸ”¥ åŸ·è¡Œé ç†±è«‹æ±‚...")
        warmup_case = TEST_CASES[0]
        await test_single_request(client, warmup_case, 0)
        await asyncio.sleep(2)
        
        # åŸ·è¡Œæ¸¬è©¦
        all_results = []
        
        for test_case in TEST_CASES:
            print(f"\nğŸ“ æ¸¬è©¦æ¡ˆä¾‹: {test_case['name']}")
            print(f"   èªè¨€: {test_case['language']}")
            print(f"   JDé•·åº¦: {len(test_case['job_description'])} å­—å…ƒ")
            
            case_results = []
            
            for i in range(iterations):
                result = await test_single_request(client, test_case, i + 1)
                case_results.append(result)
                
                if result["status"] == "success":
                    print(f"   âœ… è¿­ä»£ {i+1}: {result['total_time_ms']:.0f}ms "
                          f"(API: {result['api_processing_ms']:.0f}ms, "
                          f"Cache: {'Hit' if result['cache_hit'] else 'Miss'})")
                else:
                    print(f"   âŒ è¿­ä»£ {i+1}: {result['status']} - {result.get('error', 'N/A')}")
                
                # é¿å…å¤ªå¿«çš„è«‹æ±‚
                if i < iterations - 1:
                    await asyncio.sleep(1)
            
            all_results.extend(case_results)
            
            # è¨ˆç®—çµ±è¨ˆæ•¸æ“š
            success_results = [r for r in case_results if r["status"] == "success"]
            if success_results:
                api_times = [r["api_processing_ms"] for r in success_results]
                total_times = [r["total_time_ms"] for r in success_results]
                
                print(f"\n   ğŸ“Š çµ±è¨ˆæ‘˜è¦:")
                print(f"   æˆåŠŸç‡: {len(success_results)}/{len(case_results)} "
                      f"({len(success_results)/len(case_results)*100:.0f}%)")
                print(f"   API è™•ç†æ™‚é–“: å¹³å‡ {statistics.mean(api_times):.0f}ms, "
                      f"ä¸­ä½æ•¸ {statistics.median(api_times):.0f}ms")
                print(f"   ç¸½å›æ‡‰æ™‚é–“: å¹³å‡ {statistics.mean(total_times):.0f}ms, "
                      f"ä¸­ä½æ•¸ {statistics.median(total_times):.0f}ms")
    
    # ä¿å­˜çµæœ
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_file = f"staging_performance_test_{timestamp}.json"
    
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(all_results, f, ensure_ascii=False, indent=2)
    
    print(f"\nğŸ’¾ æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: {output_file}")
    
    # ç”Ÿæˆè©³ç´°å ±å‘Š
    generate_detailed_report(all_results)

def generate_detailed_report(results: List[Dict[str, Any]]):
    """ç”Ÿæˆè©³ç´°çš„æ•ˆèƒ½å ±å‘Š"""
    
    print("\n" + "="*60)
    print("ğŸ“Š è©³ç´°æ•ˆèƒ½åˆ†æå ±å‘Š")
    print("="*60)
    
    # æŒ‰æ¸¬è©¦æ¡ˆä¾‹åˆ†çµ„
    case_groups = defaultdict(list)
    for result in results:
        if result["status"] == "success":
            case_groups[result["test_case"]].append(result)
    
    for case_name, case_results in case_groups.items():
        print(f"\n### {case_name}")
        
        # æ™‚é–“åˆ†è§£åˆ†æ
        print("\nâ±ï¸  æ™‚é–“åˆ†è§£ (å¹³å‡å€¼ ms):")
        
        metrics = {
            "æœå‹™åˆå§‹åŒ–": [r["service_init_ms"] for r in case_results],
            "è«‹æ±‚é©—è­‰": [r["validation_ms"] for r in case_results],
            "èªè¨€æª¢æ¸¬": [r["language_detection_ms"] for r in case_results],
            "é—œéµå­—æå–": [r["extraction_ms"] for r in case_results],
            "API ç¸½è™•ç†": [r["api_processing_ms"] for r in case_results],
            "ç«¯åˆ°ç«¯ç¸½æ™‚é–“": [r["total_time_ms"] for r in case_results]
        }
        
        for metric_name, values in metrics.items():
            if values and all(v is not None for v in values):
                avg = statistics.mean(values)
                print(f"   {metric_name}: {avg:.1f}ms")
        
        # å¿«å–åˆ†æ
        cache_hits = sum(1 for r in case_results if r["cache_hit"])
        print(f"\nğŸ’¾ å¿«å–å‘½ä¸­ç‡: {cache_hits}/{len(case_results)} "
              f"({cache_hits/len(case_results)*100:.0f}%)")
        
        # æ•ˆèƒ½ç“¶é ¸åˆ†æ
        if case_results:
            avg_extraction = statistics.mean([r["extraction_ms"] for r in case_results])
            avg_total = statistics.mean([r["api_processing_ms"] for r in case_results])
            extraction_percentage = (avg_extraction / avg_total) * 100
            
            print(f"\nğŸ¯ æ•ˆèƒ½ç“¶é ¸:")
            print(f"   é—œéµå­—æå–ä½”ç¸½æ™‚é–“: {extraction_percentage:.1f}%")
            
            if extraction_percentage > 80:
                print("   âš ï¸  LLM èª¿ç”¨æ˜¯ä¸»è¦ç“¶é ¸")
            elif extraction_percentage > 60:
                print("   âš¡ LLM èª¿ç”¨ä½”ç”¨å¤§éƒ¨åˆ†æ™‚é–“")
            else:
                print("   âœ… æ™‚é–“åˆ†é…ç›¸å°å‡è¡¡")

if __name__ == "__main__":
    asyncio.run(run_performance_tests(iterations=2))