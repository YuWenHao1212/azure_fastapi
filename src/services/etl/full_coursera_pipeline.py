# flake8: noqa
"""
å®Œæ•´çš„ Coursera ETL + Embedding Pipeline
åŒ…å«æ¸¬è©¦æ¨¡å¼ï¼ˆ3å€‹èª²ç¨‹ï¼‰å’Œå®Œæ•´æ¨¡å¼ï¼ˆæ‰€æœ‰èª²ç¨‹ï¼‰
ETL script with CLI output - print statements are intentional
"""
import asyncio
import json
import os
import signal
import sys
from datetime import datetime
from typing import Any

import aiohttp
import asyncpg
from pgvector.asyncpg import register_vector

sys.path.append('.')
from src.services.embedding_client import get_azure_embedding_client


class CourseraFullPipeline:
    """å®Œæ•´çš„ Coursera è³‡æ–™è™•ç† Pipeline"""
    
    def __init__(self, test_mode: bool = False):
        # Impact.com API è¨­å®š
        self.base_url = "https://api.impact.com"
        self.account_sid = "IR5reNPSapi65901857xTcusvceeZxhuj1"
        self.auth_token = os.getenv("IMPACT_API_TOKEN", "fqCf-KbEjMdGzihWtHURf2~mnTCNb9jd")
        self.catalog_id = "9419"
        
        # æ¨¡å¼è¨­å®š
        self.test_mode = test_mode
        self.max_courses = 3 if test_mode else None  # æ¸¬è©¦æ¨¡å¼åªè™•ç† 3 å€‹
        
        # çµ±è¨ˆè³‡è¨Š
        self.stats = {
            "start_time": None,
            "end_time": None,
            "courses_fetched": 0,
            "courses_saved": 0,
            "embeddings_created": 0,
            "errors": []
        }
        
        # ä¸­æ–·è™•ç†
        self.should_stop = False
        
        # é€²åº¦æª”æ¡ˆ
        self.progress_file = "temp/etl_progress.json"
        
    def handle_interrupt(self, signum, frame):
        """è™•ç†ä¸­æ–·ä¿¡è™Ÿ"""
        print("\n\nâš ï¸  æ”¶åˆ°ä¸­æ–·ä¿¡è™Ÿï¼Œæ­£åœ¨å„ªé›…åœ°åœæ­¢...")
        self.should_stop = True
        self._save_progress()
        
    def _save_progress(self):
        """å„²å­˜é€²åº¦"""
        # è½‰æ› datetime ç‚ºå­—ä¸²
        stats_copy = self.stats.copy()
        if stats_copy.get("start_time"):
            stats_copy["start_time"] = stats_copy["start_time"].isoformat()
        if stats_copy.get("end_time"):
            stats_copy["end_time"] = stats_copy["end_time"].isoformat()
        
        progress = {
            "timestamp": datetime.now().isoformat(),
            "mode": "test" if self.test_mode else "full",
            "stats": stats_copy,
            "status": "interrupted" if self.should_stop else "running"
        }
        
        with open(self.progress_file, 'w') as f:
            json.dump(progress, f, indent=2)
        
        print(f"ğŸ’¾ é€²åº¦å·²å„²å­˜åˆ° {self.progress_file}")
    
    async def run(self):
        """åŸ·è¡Œå®Œæ•´ Pipeline"""
        print("ğŸš€ Coursera ETL + Embedding Pipeline")
        print(f"   æ¨¡å¼: {'æ¸¬è©¦ (3å€‹èª²ç¨‹)' if self.test_mode else 'å®Œæ•´ (æ‰€æœ‰èª²ç¨‹)'}")
        print(f"   æ™‚é–“: {datetime.now()}")
        print("=" * 60)
        
        self.stats["start_time"] = datetime.now()
        
        # è¨­å®šä¸­æ–·è™•ç†
        signal.signal(signal.SIGINT, self.handle_interrupt)
        
        try:
            # æ­¥é©Ÿ 1: æª¢æŸ¥ç¾æœ‰è³‡æ–™
            await self._check_existing_data()
            
            if self.should_stop:
                return
            
            # æ­¥é©Ÿ 2: å¾ API æŠ“å–èª²ç¨‹
            courses = await self._fetch_courses()
            
            if self.should_stop or not courses:
                return
            
            # æ­¥é©Ÿ 3: å„²å­˜èª²ç¨‹åˆ°è³‡æ–™åº«
            await self._save_courses(courses)
            
            if self.should_stop:
                return
            
            # æ­¥é©Ÿ 4: ç”¢ç”Ÿ embeddings
            await self._generate_embeddings()
            
            # å®Œæˆ
            self.stats["end_time"] = datetime.now()
            self._print_summary()
            
        except Exception as e:
            print(f"\nâŒ Pipeline éŒ¯èª¤: {e}")
            self.stats["errors"].append(str(e))
            import traceback
            traceback.print_exc()
        
        finally:
            self._save_progress()
    
    async def _check_existing_data(self):
        """æª¢æŸ¥ç¾æœ‰è³‡æ–™"""
        print("\nğŸ“Š æª¢æŸ¥ç¾æœ‰è³‡æ–™...")
        
        conn = await self._get_db_connection()
        try:
            # æª¢æŸ¥èª²ç¨‹æ•¸é‡
            course_count = await conn.fetchval(
                "SELECT COUNT(*) FROM courses WHERE platform_id = 'coursera'"
            )
            
            # æª¢æŸ¥ embeddings
            embedding_count = await conn.fetchval("""
                SELECT COUNT(*) FROM courses c
                JOIN course_embeddings ce ON c.id = ce.course_id
                WHERE c.platform_id = 'coursera'
            """)
            
            print(f"   ç¾æœ‰èª²ç¨‹: {course_count}")
            print(f"   å·²æœ‰ embeddings: {embedding_count}")
            
            if self.test_mode:
                print("   âš ï¸  æ¸¬è©¦æ¨¡å¼ï¼šå°‡åªè™•ç†å‰ 3 å€‹æ–°èª²ç¨‹")
            elif course_count >= 8760:
                print("   âœ… è³‡æ–™å·²å®Œæ•´ï¼")
                response = input("\nè¦é‡æ–°åŸ·è¡Œå—ï¼Ÿ(y/N): ")
                if response.lower() != 'y':
                    self.should_stop = True
                    
        finally:
            await conn.close()
    
    async def _fetch_courses(self) -> list[dict[str, Any]]:
        """å¾ Impact.com API æŠ“å–èª²ç¨‹"""
        print("\nğŸ“¥ å¾ Impact.com API æŠ“å–èª²ç¨‹...")
        
        courses = []
        page = 1
        fetched_count = 0
        
        async with aiohttp.ClientSession() as session:
            while not self.should_stop:
                if self.test_mode and fetched_count >= self.max_courses:
                    break
                
                url = f"{self.base_url}/Mediapartners/{self.account_sid}/Catalogs/{self.catalog_id}/Items"
                params = {
                    "PageSize": 100,
                    "Page": page
                }
                
                print(f"   æŠ“å–ç¬¬ {page} é ...", end="", flush=True)
                
                try:
                    async with session.get(
                        url,
                        params=params,
                        auth=aiohttp.BasicAuth(self.account_sid, self.auth_token),
                        headers={"Accept": "application/json"},
                        timeout=aiohttp.ClientTimeout(total=60)
                    ) as response:
                        if response.status != 200:
                            print(f" âŒ éŒ¯èª¤ {response.status}")
                            break
                        
                        data = await response.json()
                        items = data.get("Items", [])
                        
                        # æ¸¬è©¦æ¨¡å¼ä¸‹åªå–éœ€è¦çš„æ•¸é‡
                        if self.test_mode:
                            items = items[:self.max_courses - fetched_count]
                        
                        courses.extend(items)
                        fetched_count += len(items)
                        
                        print(f" âœ“ ({len(items)} å€‹) - ç´¯è¨ˆ: {fetched_count}")
                        
                        # æª¢æŸ¥æ˜¯å¦é‚„æœ‰æ›´å¤šé é¢
                        total_pages = int(data.get("@numpages", 1))
                        if page >= total_pages:
                            break
                        
                        page += 1
                        
                        # æ¯ 10 é å„²å­˜é€²åº¦
                        if page % 10 == 0:
                            self.stats["courses_fetched"] = fetched_count
                            self._save_progress()
                        
                        # é€Ÿç‡é™åˆ¶å’Œ API é™åˆ¶æª¢æŸ¥
                        await asyncio.sleep(1.0)  # å¢åŠ å»¶é²ï¼Œæ›´ä¿å®ˆ
                        
                        # æª¢æŸ¥ rate limitï¼ˆå¾ response headersï¼‰
                        remaining = response.headers.get('x-ratelimit-remaining-hour')
                        if remaining and int(remaining) < 100:
                            print(f"\nâš ï¸  API é€Ÿç‡é™åˆ¶æ¥è¿‘ä¸Šé™ï¼Œå‰©é¤˜: {remaining}/1000")
                            print("   æš«åœ 60 ç§’...")
                            await asyncio.sleep(60)
                        
                except Exception as e:
                    print(f" âŒ éŒ¯èª¤: {e}")
                    self.stats["errors"].append(f"API fetch error: {e}")
                    break
        
        self.stats["courses_fetched"] = len(courses)
        print(f"\nâœ… æˆåŠŸæŠ“å– {len(courses)} å€‹èª²ç¨‹")
        return courses
    
    async def _save_courses(self, courses: list[dict[str, Any]]):
        """å„²å­˜èª²ç¨‹åˆ°è³‡æ–™åº«"""
        print(f"\nğŸ’¾ å„²å­˜ {len(courses)} å€‹èª²ç¨‹åˆ°è³‡æ–™åº«...")
        
        conn = await self._get_db_connection()
        
        try:
            saved_count = 0
            
            for i, raw_course in enumerate(courses):
                if self.should_stop:
                    break
                
                try:
                    # è½‰æ›èª²ç¨‹è³‡æ–™
                    course = self._transform_course(raw_course)
                    
                    # å„²å­˜åˆ°è³‡æ–™åº«
                    await self._save_single_course(conn, course)
                    saved_count += 1
                    
                    # é¡¯ç¤ºé€²åº¦
                    if (i + 1) % 10 == 0 or i == len(courses) - 1:
                        progress = (i + 1) / len(courses) * 100
                        print(f"   é€²åº¦: {progress:.1f}% ({i + 1}/{len(courses)})")
                        
                except Exception as e:
                    print(f"   âš ï¸  å„²å­˜éŒ¯èª¤: {raw_course.get('Name', 'Unknown')} - {e}")
                    self.stats["errors"].append(f"Save error: {e}")
            
            self.stats["courses_saved"] = saved_count
            print(f"âœ… æˆåŠŸå„²å­˜ {saved_count} å€‹èª²ç¨‹")
            
        finally:
            await conn.close()
    
    def _transform_course(self, raw: dict[str, Any]) -> dict[str, Any]:
        """è½‰æ›èª²ç¨‹è³‡æ–™æ ¼å¼"""
        return {
            "platform_id": "coursera",
            "external_id": raw.get("CatalogItemId", ""),
            "name": raw.get("Name", ""),
            "description": self._clean_description(raw.get("Description", "")),
            "manufacturer": raw.get("Manufacturer", ""),
            "current_price": self._parse_price(raw.get("CurrentPrice", "0")),
            "original_price": self._parse_price(raw.get("OriginalPrice", "0")),
            "currency": raw.get("Currency", "USD"),
            "image_url": raw.get("ImageUrl", ""),
            "stock_status": self._normalize_stock_status(raw.get("StockAvailability", "")),
            "original_url": raw.get("Url", ""),
            "metadata": {
                "category": raw.get("Category", ""),
                "sub_category": raw.get("SubCategory", ""),
                "mpn": raw.get("Mpn", ""),
                "catalog_id": raw.get("CatalogId", ""),
                "campaign_id": raw.get("CampaignId", ""),
                "id": raw.get("Id", "")
            }
        }
    
    def _clean_description(self, desc: str) -> str:
        """æ¸…ç†æè¿°æ–‡å­—"""
        desc = desc.replace("\\n", "\n").replace("\\r", "")
        desc = desc.replace("\\'", "'").replace('\\"', '"')
        if len(desc) > 5000:
            desc = desc[:4997] + "..."
        return desc.strip()
    
    def _parse_price(self, price_str: str) -> float:
        """è§£æåƒ¹æ ¼"""
        try:
            price_str = price_str.replace("$", "").replace(",", "").strip()
            return float(price_str) if price_str else 0.0
        except (ValueError, TypeError):
            return 0.0
    
    def _normalize_stock_status(self, status: str) -> str:
        """æ¨™æº–åŒ–åº«å­˜ç‹€æ…‹"""
        status_map = {
            "InStock": "in_stock",
            "OutOfStock": "out_of_stock",
            "Limited": "limited"
        }
        return status_map.get(status, "unknown")
    
    async def _save_single_course(self, conn: asyncpg.Connection, course: dict[str, Any]):
        """å„²å­˜å–®ä¸€èª²ç¨‹"""
        course_id = f"{course['platform_id']}_{course['external_id']}"
        
        # ä½¿ç”¨ UPSERT
        await conn.execute("""
            INSERT INTO courses (
                id, platform_id, external_id, name, description,
                manufacturer, current_price, original_price,
                currency, image_url, stock_status, metadata
            ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
            ON CONFLICT (id) DO UPDATE SET
                name = EXCLUDED.name,
                description = EXCLUDED.description,
                manufacturer = EXCLUDED.manufacturer,
                current_price = EXCLUDED.current_price,
                original_price = EXCLUDED.original_price,
                currency = EXCLUDED.currency,
                image_url = EXCLUDED.image_url,
                stock_status = EXCLUDED.stock_status,
                metadata = EXCLUDED.metadata,
                last_synced = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP
        """,
        course_id,
        course['platform_id'],
        course['external_id'],
        course['name'],
        course['description'],
        course['manufacturer'],
        course['current_price'],
        course['original_price'],
        course['currency'],
        course['image_url'],
        course['stock_status'],
        json.dumps(course['metadata'])
        )
        
        # å„²å­˜è¿½è¹¤ URL
        if course.get('original_url'):
            await conn.execute("""
                INSERT INTO course_tracking_urls 
                (course_id, original_url, tracking_url, tracking_params)
                VALUES ($1, $2, $3, $4)
                ON CONFLICT DO NOTHING
            """,
            course_id,
            course['original_url'],
            course['original_url'],
            json.dumps({})
            )
    
    async def _generate_embeddings(self):
        """ç”¢ç”Ÿ embeddings"""
        print("\nğŸ§® ç”¢ç”Ÿèª²ç¨‹ Embeddings...")
        
        conn = await self._get_db_connection()
        await register_vector(conn)
        
        try:
            # å–å¾—éœ€è¦ç”¢ç”Ÿ embedding çš„èª²ç¨‹
            courses = await conn.fetch("""
                SELECT c.id, c.name, c.description, c.manufacturer,
                       c.metadata->>'category' as category
                FROM courses c
                LEFT JOIN course_embeddings ce ON c.id = ce.course_id
                WHERE ce.course_id IS NULL
                AND c.platform_id = 'coursera'
                ORDER BY c.created_at
                LIMIT $1
            """, self.max_courses if self.test_mode else 10000)
            
            if not courses:
                print("   âœ… æ‰€æœ‰èª²ç¨‹éƒ½å·²æœ‰ embeddings")
                return
            
            print(f"   æ‰¾åˆ° {len(courses)} å€‹éœ€è¦ç”¢ç”Ÿ embedding çš„èª²ç¨‹")
            
            # åˆå§‹åŒ– embedding client
            embedding_client = get_azure_embedding_client()
            
            try:
                # æ‰¹æ¬¡è™•ç†
                batch_size = 5
                for i in range(0, len(courses), batch_size):
                    if self.should_stop:
                        break
                    
                    batch = courses[i:i + batch_size]
                    await self._process_embedding_batch(conn, embedding_client, batch)
                    
                    # é¡¯ç¤ºé€²åº¦
                    progress = min((i + batch_size) / len(courses) * 100, 100)
                    processed = min(i + batch_size, len(courses))
                    print(f"   Embedding é€²åº¦: {progress:.1f}% ({processed}/{len(courses)})")
                    
                    # é€Ÿç‡é™åˆ¶
                    await asyncio.sleep(1)
                    
            finally:
                await embedding_client.close()
                
        finally:
            await conn.close()
    
    async def _process_embedding_batch(self, conn: asyncpg.Connection, 
                                     embedding_client, batch: list[Any]):
        """è™•ç†ä¸€æ‰¹ embeddings"""
        texts = []
        valid_courses = []
        
        for course in batch:
            # å»ºç«‹ embedding æ–‡æœ¬
            text = f"Course Title: {course['name']} | Provider: {course['manufacturer']}"
            if course['category']:
                text += f" | Category: {course['category']}"
            if course['description']:
                text += f" | Description: {course['description'][:1500]}"
            
            texts.append(text)
            valid_courses.append(course)
        
        try:
            # ç”¢ç”Ÿ embeddings
            embeddings = await embedding_client.create_embeddings(texts)
            
            # å„²å­˜åˆ°è³‡æ–™åº«
            for course, embedding in zip(valid_courses, embeddings, strict=False):
                await conn.execute("""
                    INSERT INTO course_embeddings 
                    (course_id, embedding, embedding_model)
                    VALUES ($1, $2::vector, $3)
                    ON CONFLICT (course_id) DO UPDATE
                    SET embedding = EXCLUDED.embedding,
                        created_at = CURRENT_TIMESTAMP
                """,
                course['id'],
                embedding,
                'text-embedding-3-large'
                )
                
            self.stats["embeddings_created"] += len(valid_courses)
            
        except Exception as e:
            print(f"   âš ï¸  Embedding æ‰¹æ¬¡éŒ¯èª¤: {e}")
            self.stats["errors"].append(f"Embedding error: {e}")
    
    async def _get_db_connection(self) -> asyncpg.Connection:
        """å–å¾—è³‡æ–™åº«é€£ç·š"""
        with open('temp/postgres_connection.json') as f:
            conn_info = json.load(f)
        
        return await asyncpg.connect(
            host=conn_info['host'],
            database=conn_info['database'],
            user=conn_info['user'],
            password=conn_info['password'],
            ssl='require'
        )
    
    def _print_summary(self):
        """åˆ—å°åŸ·è¡Œæ‘˜è¦"""
        duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
        
        print("\n" + "=" * 60)
        print("ğŸ“Š åŸ·è¡Œæ‘˜è¦")
        print("=" * 60)
        print(f"æ¨¡å¼: {'æ¸¬è©¦' if self.test_mode else 'å®Œæ•´'}")
        print(f"åŸ·è¡Œæ™‚é–“: {duration:.2f} ç§’")
        print(f"æŠ“å–èª²ç¨‹: {self.stats['courses_fetched']}")
        print(f"å„²å­˜èª²ç¨‹: {self.stats['courses_saved']}")
        print(f"ç”¢ç”Ÿ Embeddings: {self.stats['embeddings_created']}")
        print(f"éŒ¯èª¤æ•¸é‡: {len(self.stats['errors'])}")
        
        if self.stats['errors']:
            print("\néŒ¯èª¤è©³æƒ…:")
            for i, error in enumerate(self.stats['errors'][:5], 1):
                print(f"  {i}. {error}")
            if len(self.stats['errors']) > 5:
                print(f"  ... é‚„æœ‰ {len(self.stats['errors']) - 5} å€‹éŒ¯èª¤")


async def main():
    """ä¸»ç¨‹å¼"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Coursera ETL + Embedding Pipeline')
    parser.add_argument('--test', action='store_true', help='æ¸¬è©¦æ¨¡å¼ï¼ˆåªè™•ç†3å€‹èª²ç¨‹ï¼‰')
    parser.add_argument('--full', action='store_true', help='å®Œæ•´æ¨¡å¼ï¼ˆè™•ç†æ‰€æœ‰èª²ç¨‹ï¼‰')
    
    args = parser.parse_args()
    
    if not args.test and not args.full:
        print("è«‹æŒ‡å®šæ¨¡å¼:")
        print("  --test  æ¸¬è©¦æ¨¡å¼ï¼ˆ3å€‹èª²ç¨‹ï¼‰")
        print("  --full  å®Œæ•´æ¨¡å¼ï¼ˆæ‰€æœ‰èª²ç¨‹ï¼‰")
        return
    
    # åŸ·è¡Œ pipeline
    pipeline = CourseraFullPipeline(test_mode=args.test)
    await pipeline.run()


if __name__ == "__main__":
    asyncio.run(main())