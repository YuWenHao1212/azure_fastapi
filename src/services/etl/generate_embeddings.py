# flake8: noqa
"""
ç”¢ç”Ÿèª²ç¨‹ embeddings ä¸¦å„²å­˜åˆ°è³‡æ–™åº«
ETL script with CLI output - print statements are intentional
"""
import asyncio
import json
from datetime import datetime
from typing import Any

import asyncpg
import numpy as np

from src.core.monitoring_service import monitoring_service
from src.services.embedding_client import get_azure_embedding_client


class CourseEmbeddingGenerator:
    """èª²ç¨‹ Embedding ç”¢ç”Ÿå™¨"""
    
    def __init__(self, batch_size: int = 16):
        self.batch_size = batch_size
        self.embedding_client = None
        self.stats = {
            "total_courses": 0,
            "processed": 0,
            "skipped": 0,
            "errors": 0,
            "start_time": None,
            "end_time": None
        }
    
    async def run(self):
        """åŸ·è¡Œ embedding ç”¢ç”Ÿæµç¨‹"""
        print(f"ğŸš€ é–‹å§‹ç”¢ç”Ÿèª²ç¨‹ Embeddings - {datetime.now()}")
        print("=" * 60)
        
        self.stats["start_time"] = datetime.now()
        
        try:
            # å–å¾—éœ€è¦ç”¢ç”Ÿ embedding çš„èª²ç¨‹
            courses = await self._get_courses_without_embeddings()
            self.stats["total_courses"] = len(courses)
            
            if not courses:
                print("âœ… æ‰€æœ‰èª²ç¨‹éƒ½å·²æœ‰ embeddingsï¼")
                return
            
            print(f"ğŸ“š æ‰¾åˆ° {len(courses)} å€‹éœ€è¦ç”¢ç”Ÿ embedding çš„èª²ç¨‹")
            
            # åˆå§‹åŒ– embedding client
            self.embedding_client = get_azure_embedding_client()
            
            # æ‰¹æ¬¡è™•ç†
            for i in range(0, len(courses), self.batch_size):
                batch = courses[i:i + self.batch_size]
                await self._process_batch(batch)
                
                # é¡¯ç¤ºé€²åº¦
                progress = (i + len(batch)) / len(courses) * 100
                processed = i + len(batch)
                print(f"\né€²åº¦: {progress:.1f}% ({processed}/{len(courses)})")
                print(f"å·²è™•ç†: {self.stats['processed']} | è·³é: {self.stats['skipped']} | éŒ¯èª¤: {self.stats['errors']}")
                
                # é€Ÿç‡é™åˆ¶
                await asyncio.sleep(1)
            
        finally:
            if self.embedding_client:
                await self.embedding_client.close()
            
            self.stats["end_time"] = datetime.now()
            duration = (self.stats["end_time"] - self.stats["start_time"]).total_seconds()
            
            print("\n" + "=" * 60)
            print("âœ… Embedding ç”¢ç”Ÿå®Œæˆï¼")
            print(f"   ç¸½æ™‚é–“: {duration:.2f} ç§’")
            print(f"   ç¸½èª²ç¨‹æ•¸: {self.stats['total_courses']}")
            print(f"   å·²è™•ç†: {self.stats['processed']}")
            print(f"   è·³é: {self.stats['skipped']}")
            print(f"   éŒ¯èª¤: {self.stats['errors']}")
    
    async def _get_courses_without_embeddings(self) -> list[dict[str, Any]]:
        """å–å¾—æ²’æœ‰ embeddings çš„èª²ç¨‹"""
        # è®€å–é€£ç·šè³‡è¨Š
        with open('temp/postgres_connection.json') as f:
            conn_info = json.load(f)
        
        conn = await asyncpg.connect(
            host=conn_info['host'],
            database=conn_info['database'],
            user=conn_info['user'],
            password=conn_info['password'],
            ssl='require'
        )
        
        try:
            # æŸ¥è©¢æ²’æœ‰ embedding çš„èª²ç¨‹
            rows = await conn.fetch("""
                SELECT c.id, c.name, c.description, c.manufacturer, 
                       c.metadata->>'category' as category
                FROM courses c
                LEFT JOIN course_embeddings ce ON c.id = ce.course_id
                WHERE ce.course_id IS NULL
                AND c.platform_id = 'coursera'
                ORDER BY c.created_at
                LIMIT 1000
            """)
            
            courses = []
            for row in rows:
                courses.append({
                    "id": row["id"],
                    "name": row["name"],
                    "description": row["description"],
                    "manufacturer": row["manufacturer"],
                    "category": row["category"] or ""
                })
            
            return courses
            
        finally:
            await conn.close()
    
    async def _process_batch(self, batch: list[dict[str, Any]]):
        """è™•ç†ä¸€æ‰¹èª²ç¨‹"""
        print(f"\nğŸ”„ è™•ç†æ‰¹æ¬¡ ({len(batch)} å€‹èª²ç¨‹)...")
        
        # æº–å‚™æ–‡æœ¬
        texts = []
        valid_courses = []
        
        for course in batch:
            # å»ºç«‹ç”¨æ–¼ embedding çš„æ–‡æœ¬
            text = self._create_embedding_text(course)
            
            if len(text) > 10:  # ç¢ºä¿æœ‰è¶³å¤ çš„å…§å®¹
                texts.append(text)
                valid_courses.append(course)
            else:
                print(f"   âš ï¸  è·³é: {course['name'][:50]} (å…§å®¹ä¸è¶³)")
                self.stats["skipped"] += 1
        
        if not texts:
            return
        
        try:
            # ç”¢ç”Ÿ embeddings
            print(f"   ğŸ§® ç”¢ç”Ÿ {len(texts)} å€‹ embeddings...")
            start_time = datetime.now()
            
            embeddings = await self.embedding_client.create_embeddings(texts)
            
            duration = (datetime.now() - start_time).total_seconds()
            print(f"   âœ… å®Œæˆï¼è€—æ™‚: {duration:.2f} ç§’")
            
            # å„²å­˜åˆ°è³‡æ–™åº«
            await self._save_embeddings(valid_courses, embeddings)
            
            self.stats["processed"] += len(valid_courses)
            
            # è¿½è¹¤æŒ‡æ¨™
            monitoring_service.track_event(
                "CourseEmbeddingGeneration",
                {
                    "batch_size": len(valid_courses),
                    "duration_seconds": duration,
                    "tokens_estimated": sum(len(text) // 4 for text in texts)
                }
            )
            
        except Exception as e:
            print(f"   âŒ æ‰¹æ¬¡è™•ç†éŒ¯èª¤: {e}")
            self.stats["errors"] += len(batch)
            
            # è¨˜éŒ„éŒ¯èª¤çš„èª²ç¨‹
            for course in batch:
                print(f"      - {course['name'][:50]}")
    
    def _create_embedding_text(self, course: dict[str, Any]) -> str:
        """å»ºç«‹ç”¨æ–¼ embedding çš„æ–‡æœ¬"""
        # çµ„åˆç›¸é—œæ¬„ä½ï¼Œçµ¦äºˆä¸åŒæ¬Šé‡
        parts = []
        
        # èª²ç¨‹åç¨± (æœ€é‡è¦)
        if course.get('name'):
            parts.append(f"Course Title: {course['name']}")
        
        # æä¾›è€…
        if course.get('manufacturer'):
            parts.append(f"Provider: {course['manufacturer']}")
        
        # é¡åˆ¥
        if course.get('category'):
            parts.append(f"Category: {course['category']}")
        
        # æè¿° (é™åˆ¶é•·åº¦é¿å… token éå¤š)
        if course.get('description'):
            desc = course['description']
            # æ¸…ç†æè¿°
            desc = desc.replace('\n', ' ').strip()
            if len(desc) > 2000:
                desc = desc[:1997] + "..."
            if desc:
                parts.append(f"Description: {desc}")
        
        return " | ".join(parts)
    
    async def _save_embeddings(self, courses: list[dict[str, Any]], embeddings: list[list[float]]):
        """å„²å­˜ embeddings åˆ°è³‡æ–™åº«"""
        # è®€å–é€£ç·šè³‡è¨Š
        with open('temp/postgres_connection.json') as f:
            conn_info = json.load(f)
        
        # éœ€è¦å…ˆè¨»å†Š pgvector é¡å‹
        from pgvector.asyncpg import register_vector
        
        conn = await asyncpg.connect(
            host=conn_info['host'],
            database=conn_info['database'],
            user=conn_info['user'],
            password=conn_info['password'],
            ssl='require'
        )
        
        try:
            # è¨»å†Š vector é¡å‹
            await register_vector(conn)
            
            # æ‰¹æ¬¡æ’å…¥
            async with conn.transaction():
                for course, embedding in zip(courses, embeddings, strict=False):
                    # ç¢ºä¿ embedding æ˜¯æ­£ç¢ºçš„æ ¼å¼
                    embedding_array = np.array(embedding, dtype=np.float32)
                    
                    await conn.execute("""
                        INSERT INTO course_embeddings 
                        (course_id, embedding, embedding_model)
                        VALUES ($1, $2::vector, $3)
                        ON CONFLICT (course_id) DO UPDATE
                        SET embedding = EXCLUDED.embedding,
                            created_at = CURRENT_TIMESTAMP
                    """,
                    course['id'],
                    embedding_array.tolist(),
                    'text-embedding-3-large'
                    )
                    
            print(f"   ğŸ’¾ å·²å„²å­˜ {len(courses)} å€‹ embeddings")
            
        finally:
            await conn.close()


async def check_embedding_status():
    """æª¢æŸ¥ embedding ç‹€æ…‹"""
    with open('temp/postgres_connection.json') as f:
        conn_info = json.load(f)
    
    conn = await asyncpg.connect(
        host=conn_info['host'],
        database=conn_info['database'],
        user=conn_info['user'],
        password=conn_info['password'],
        ssl='require'
    )
    
    try:
        # çµ±è¨ˆè³‡è¨Š
        total_courses = await conn.fetchval(
            "SELECT COUNT(*) FROM courses WHERE platform_id = 'coursera'"
        )
        
        courses_with_embeddings = await conn.fetchval("""
            SELECT COUNT(*) 
            FROM courses c
            JOIN course_embeddings ce ON c.id = ce.course_id
            WHERE c.platform_id = 'coursera'
        """)
        
        print("\nğŸ“Š Embedding ç‹€æ…‹:")
        print(f"   ç¸½èª²ç¨‹æ•¸: {total_courses}")
        print(f"   å·²æœ‰ embedding: {courses_with_embeddings}")
        print(f"   å¾…è™•ç†: {total_courses - courses_with_embeddings}")
        
        # é¡¯ç¤ºç¯„ä¾‹
        if courses_with_embeddings > 0:
            sample = await conn.fetchrow("""
                SELECT c.name, c.manufacturer,
                       LENGTH(ce.embedding::text) as embedding_size
                FROM courses c
                JOIN course_embeddings ce ON c.id = ce.course_id
                WHERE c.platform_id = 'coursera'
                LIMIT 1
            """)
            
            print("\nğŸ“– ç¯„ä¾‹:")
            print(f"   èª²ç¨‹: {sample['name']}")
            print(f"   æä¾›è€…: {sample['manufacturer']}")
            print("   Embedding å¤§å°: ~1536 ç¶­åº¦")
        
    finally:
        await conn.close()


async def main():
    """ä¸»ç¨‹å¼"""
    # æª¢æŸ¥ç›®å‰ç‹€æ…‹
    await check_embedding_status()
    
    # è©¢å•æ˜¯å¦ç¹¼çºŒ
    response = input("\nè¦é–‹å§‹ç”¢ç”Ÿ embeddings å—ï¼Ÿ(y/N): ")
    if response.lower() != 'y':
        print("å·²å–æ¶ˆã€‚")
        return
    
    # åŸ·è¡Œç”¢ç”Ÿå™¨
    generator = CourseEmbeddingGenerator(batch_size=10)  # å°æ‰¹æ¬¡é¿å…è¶…æ™‚
    await generator.run()
    
    # é¡¯ç¤ºæœ€çµ‚ç‹€æ…‹
    await check_embedding_status()


if __name__ == "__main__":
    asyncio.run(main())