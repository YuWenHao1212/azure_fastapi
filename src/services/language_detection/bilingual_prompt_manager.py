"""
Bilingual prompt management for keyword extraction.
Manages language-specific prompts for English and Traditional Chinese.
"""

import json
import logging
from pathlib import Path
from typing import Any, NamedTuple

logger = logging.getLogger(__name__)


class PromptConfig(NamedTuple):
    """Configuration for a specific prompt version."""
    version: str
    language: str
    content: str
    metadata: dict[str, Any]


class BilingualPromptManager:
    """
    Manages bilingual prompts for keyword extraction.
    
    Supports:
    - English prompts (en): v1.0.0, v1.1.0, v1.2.0
    - Traditional Chinese prompts (zh-TW): v1.2.0-zh-TW
    """
    
    SUPPORTED_LANGUAGES = ["en", "zh-TW"]
    DEFAULT_VERSION = "latest"
    
    def __init__(self, prompt_base_path: str | None = None):
        """
        Initialize bilingual prompt manager.
        
        Args:
            prompt_base_path: Base path for prompt configuration files
        """
        self.prompt_base_path = prompt_base_path or "src/prompts"
        self._prompt_cache: dict[str, PromptConfig] = {}
        self._version_mapping = {
            "en": {
                "latest": "1.3.0",
                "1.0.0": "1.0.0",
                "1.1.0": "1.1.0", 
                "1.2.0": "1.2.0",
                "1.3.0": "1.3.0"
            },
            "zh-TW": {
                "latest": "1.3.0",
                "1.2.0": "1.2.0",
                "1.3.0": "1.3.0",
                "1.4.0": "1.4.0"
            }
        }
        
        # Initialize built-in prompts
        self._init_builtin_prompts()
    
    def _init_builtin_prompts(self):
        """Initialize built-in prompt configurations."""
        # English v1.2.0 prompt (latest) - with full consistency rules
        english_prompt = """You are an expert keyword extractor. CONSISTENCY is your TOP PRIORITY.
    
CRITICAL RULES FOR CONSISTENCY:

1. CASING RULES (MUST FOLLOW):
   - Use Title Case for all multi-word terms: "Data Analysis", "Machine Learning"
   - Keep acronyms in UPPERCASE: "SQL", "AWS", "HR", "API"
   - Single words: Title Case ("Python", "Tableau", "Excel")

2. STANDARDIZATION RULES (APPLY THESE EXACTLY):
   - "Cross-functional Teams" → "Cross-Functional Collaboration"
   - "Cross-functional Collaboration" → "Cross-Functional Collaboration"
   - "Cross-Functional Teams" → "Cross-Functional Collaboration"
   - "Strategic Decision-making" → "Strategic Decision Making"
   - "Strategic Decision-Making" → "Strategic Decision Making"
   - "Dashboard Design" → "Dashboards"
   - "Dashboard Development" → "Dashboards"
   - "data visualization tools" → "Data Visualization"
   - "data visualization software" → "Data Visualization"
   - "compensation and benefits" → "Compensation and Benefits"
   - "HR compensation & benefits" → "Compensation and Benefits"
   - "Python programming" → "Python"
   - "Python development" → "Python"
   - "machine learning algorithms" → "Machine Learning"
   - "ML algorithms" → "Machine Learning"
   - "AWS cloud services" → "AWS"
   - "Amazon Web Services" → "AWS"
   - "React.js" → "React"
   - "Node.js development" → "Node.js"
   - "project management skills" → "Project Management"
   - "computer science" → "Computer Science"
   - "information management" → "Information Management"
   - "global data analysis" → "Global Data"
   - "data-driven insights" → "Insights"

3. CONSISTENCY CHECK:
   Before finalizing, verify that:
   - All similar concepts use the SAME standard form
   - Casing is consistent (Title Case)
   - No variations of the same concept

EXAMPLES OF CORRECT EXTRACTION:

Example 1:
Input: "Senior data analyst with expertise in data visualization tools, creating dashboards and strategic decision-making"
Output: {{"keywords": ["Data Analysis", "Data Visualization", "Dashboards", "Strategic Decision Making", "Senior Analyst", ...]}}

Example 2:
Input: "Cross-functional collaboration with teams, HR compensation and benefits analysis using Python programming"
Output: {{"keywords": ["Cross-Functional Collaboration", "Compensation and Benefits", "HR", "Python", "Data Analysis", ...]}}

Example 3:
Input: "Machine learning algorithms expert with AWS cloud services and React.js development skills"
Output: {{"keywords": ["Machine Learning", "AWS", "React", "Software Development", "Cloud Computing", ...]}}

Extract keywords from this job description with ABSOLUTE CONSISTENCY:

1. Extract EXACTLY 25 keywords
2. Apply ALL standardization rules
3. Use Title Case consistently
4. Rank by importance for job matching
5. Double-check for variations of the same concept

Job Description:
{job_description}

CONSISTENCY REMINDER: Review your keywords to ensure no variations like "Cross-functional Teams" vs "Cross-Functional Collaboration" exist.

Return only JSON with exactly 25 keywords: {{"keywords": ["Term1", "Term2", ..., "Term25"]}}"""
        
        self._prompt_cache["en-1.2.0"] = PromptConfig(
            version="1.2.0",
            language="en",
            content=english_prompt,
            metadata={
                "description": "English keyword extraction prompt v1.2.0",
                "target_keywords": "25",
                "focus": "technical skills, tools, frameworks",
                "created_date": "2025-07-02",
                "is_latest": True
            }
        )
        
        # Traditional Chinese v1.2.0-zh-TW prompt
        chinese_prompt = """您是專業的關鍵字提取專家。請分析以下職位描述並提取相關的專業關鍵字。

要求：
1. 提取 25 個最能代表職位要求的專業關鍵字
2. 專注於：技能、技術、工具、框架、證照、經驗水平
3. 優先考慮技術技能和硬技能，而非軟技能
4. 使用標準的業界術語（繁體中文）
5. 移除重複項目並合併相似術語
6. 格式為簡單清單，每行一個關鍵字
7. 不使用編號、項目符號或額外格式

職位描述：
{job_description}

關鍵字："""
        
        self._prompt_cache["zh-TW-1.2.0-zh-TW"] = PromptConfig(
            version="1.2.0-zh-TW",
            language="zh-TW",
            content=chinese_prompt,
            metadata={
                "description": "繁體中文關鍵字提取提示詞 v1.2.0-zh-TW",
                "target_keywords": "25",
                "focus": "技術技能、工具、框架",
                "created_date": "2025-07-02",
                "is_latest": False,
                "locale": "Taiwan"
            }
        )
        
        # Traditional Chinese v1.3.0-zh-TW prompt (latest)
        chinese_prompt_v13 = """您是專業的關鍵字提取專家。一致性是您的首要任務。

從以下職位描述中提取關鍵字，確保絕對一致性：

1. 提取精確 25 個關鍵字
2. 必須包含所有提及的程式語言和工具
3. 必須包含完整的職位頭銜（含職級）
4. 套用標準化規則（如機器學習演算法→機器學習）
5. 英文使用一致的標題大小寫（縮寫大寫）
6. 按職位匹配重要性排序
7. 仔細檢查優先關鍵字都已包含

職位描述：
{job_description}

僅回傳包含 25 個關鍵字的 JSON：{"keywords": ["詞彙1", "詞彙2", ..., "詞彙25"]}"""
        
        self._prompt_cache["zh-TW-1.3.0-zh-TW"] = PromptConfig(
            version="1.3.0-zh-TW",
            language="zh-TW",
            content=chinese_prompt_v13,
            metadata={
                "description": "繁體中文關鍵字提取提示詞 v1.3.0-zh-TW - 加強一致性版本",
                "target_keywords": "25",
                "focus": "技術技能、工具、框架、職位頭銜",
                "created_date": "2025-07-03",
                "is_latest": True,
                "locale": "Taiwan",
                "improvements": "加入標準化規則、優先提取邏輯、職級保留"
            }
        )
        
        logger.info(f"Initialized {len(self._prompt_cache)} built-in prompts")
    
    def get_prompt(self, language: str, version: str = "latest") -> PromptConfig:
        """
        Get prompt configuration for specified language and version.
        
        Args:
            language: Language code ("en" or "zh-TW")
            version: Prompt version ("latest", "1.0.0", "1.1.0", "1.2.0", "1.2.0-zh-TW")
            
        Returns:
            PromptConfig for the specified language and version
            
        Raises:
            ValueError: If language or version is not supported
        """
        if language not in self.SUPPORTED_LANGUAGES:
            raise ValueError(f"Language '{language}' not supported. Supported: {self.SUPPORTED_LANGUAGES}")
        
        # Resolve version mapping
        if language not in self._version_mapping:
            raise ValueError(f"No version mapping for language '{language}'")
        
        if version not in self._version_mapping[language]:
            available_versions = list(self._version_mapping[language].keys())
            raise ValueError(f"Version '{version}' not available for language '{language}'. Available: {available_versions}")
        
        actual_version = self._version_mapping[language][version]
        cache_key = f"{language}-{actual_version}"
        
        if cache_key not in self._prompt_cache:
            # Try to load from file
            prompt_config = self._load_prompt_from_file(language, actual_version)
            if prompt_config:
                self._prompt_cache[cache_key] = prompt_config
            else:
                raise ValueError(f"Prompt not found: {language} v{actual_version}")
        
        logger.debug(f"Retrieved prompt: {language} v{actual_version}")
        return self._prompt_cache[cache_key]
    
    def format_prompt(self, language: str, version: str, job_description: str) -> str:
        """
        Format prompt with job description for the specified language and version.
        
        Args:
            language: Language code ("en" or "zh-TW")
            version: Prompt version
            job_description: Job description text to insert
            
        Returns:
            Formatted prompt ready for LLM
        """
        prompt_config = self.get_prompt(language, version)
        
        # Format the prompt with job description
        formatted_prompt = prompt_config.content.format(job_description=job_description)
        
        logger.debug(f"Formatted prompt for {language} v{prompt_config.version}")
        return formatted_prompt
    
    def get_available_versions(self, language: str) -> list[str]:
        """
        Get available prompt versions for a language.
        
        Args:
            language: Language code
            
        Returns:
            List of available version strings
        """
        if language not in self._version_mapping:
            return []
        
        return list(self._version_mapping[language].keys())
    
    def get_latest_version(self, language: str) -> str:
        """
        Get the latest version for a language.
        
        Args:
            language: Language code
            
        Returns:
            Latest version string
        """
        if language not in self._version_mapping:
            raise ValueError(f"Language '{language}' not supported")
        
        return self._version_mapping[language]["latest"]
    
    def is_version_available(self, language: str, version: str) -> bool:
        """
        Check if a specific version is available for a language.
        
        Args:
            language: Language code
            version: Version to check
            
        Returns:
            True if version is available
        """
        if language not in self._version_mapping:
            return False
        
        return version in self._version_mapping[language]
    
    def get_prompt_metadata(self, language: str, version: str = "latest") -> dict[str, Any]:
        """
        Get metadata for a prompt configuration.
        
        Args:
            language: Language code
            version: Prompt version
            
        Returns:
            Metadata dictionary
        """
        prompt_config = self.get_prompt(language, version)
        return prompt_config.metadata.copy()
    
    def _load_prompt_from_file(self, language: str, version: str) -> PromptConfig | None:
        """
        Load prompt configuration from file.
        
        Args:
            language: Language code
            version: Version string
            
        Returns:
            PromptConfig if file exists and is valid, None otherwise
        """
        try:
            # First try YAML format (preferred)
            yaml_file = Path(self.prompt_base_path) / "keyword_extraction" / f"v{version}-{language}.yaml"
            
            if yaml_file.exists():
                import yaml
                with open(yaml_file, encoding='utf-8') as f:
                    prompt_data = yaml.safe_load(f)
                    
                # Extract system and user prompts
                prompts = prompt_data.get('prompts', {})
                system_prompt = prompts.get('system', '')
                user_prompt = prompts.get('user', '')
                
                # Combine prompts for compatibility
                full_prompt = f"{system_prompt}\n\n{user_prompt}" if system_prompt else user_prompt
                
                return PromptConfig(
                    version=version,
                    language=language,
                    content=full_prompt,
                    metadata=prompt_data.get('metadata', {})
                )
            
            # Fallback to JSON format (legacy)
            prompt_file = Path(self.prompt_base_path) / f"keyword_extraction_{language}_{version}.json"
            
            if not prompt_file.exists():
                logger.debug(f"Prompt file not found: {yaml_file} or {prompt_file}")
                return None
            
            with open(prompt_file, encoding='utf-8') as f:
                prompt_data = json.load(f)
            
            return PromptConfig(
                version=prompt_data.get("version", version),
                language=prompt_data.get("language", language),
                content=prompt_data.get("content", ""),
                metadata=prompt_data.get("metadata", {})
            )
            
        except Exception as e:
            logger.error(f"Error loading prompt file {language} v{version}: {str(e)}")
            return None
    
    def validate_prompt_format(self, prompt_content: str) -> bool:
        """
        Validate prompt format contains required placeholder.
        
        Args:
            prompt_content: Prompt content to validate
            
        Returns:
            True if prompt format is valid
        """
        required_placeholder = "{job_description}"
        return required_placeholder in prompt_content
    
    def get_all_supported_combinations(self) -> list[dict[str, str]]:
        """
        Get all supported language-version combinations.
        
        Returns:
            List of dictionaries with language and version keys
        """
        combinations = []
        
        for language in self.SUPPORTED_LANGUAGES:
            for version in self.get_available_versions(language):
                combinations.append({
                    "language": language,
                    "version": version,
                    "is_latest": version == "latest"
                })
        
        return combinations
    
    def get_cache_stats(self) -> dict[str, Any]:
        """
        Get prompt cache statistics.
        
        Returns:
            Cache statistics dictionary
        """
        return {
            "cached_prompts": len(self._prompt_cache),
            "cache_keys": list(self._prompt_cache.keys()),
            "supported_languages": self.SUPPORTED_LANGUAGES.copy(),
            "version_mappings": self._version_mapping.copy()
        }