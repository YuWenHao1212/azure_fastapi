#!/usr/bin/env python3
"""
ğŸ¯ è‡ªå‹•èªè¨€åµæ¸¬ç‰ˆæœ¬çš„ä¸€è‡´æ€§ KPI æ¸¬è©¦
æœƒæ ¹æ“š JD å…§å®¹è‡ªå‹•åµæ¸¬èªè¨€ï¼Œè€Œéå¼·åˆ¶ä½¿ç”¨æŒ‡å®šèªè¨€

ä½¿ç”¨æ–¹å¼ï¼š
    python test_consistency_kpi_auto.py              # ä½¿ç”¨é è¨­ä¸­æ–‡ JD (v1.4.0)
    python test_consistency_kpi_auto.py 1.3.0        # æŒ‡å®šç‰ˆæœ¬
    python test_consistency_kpi_auto.py 1.3.0 jd.txt # æŒ‡å®š JD æª”æ¡ˆ
"""

import asyncio
import json
import os
import sys
from collections import Counter
from datetime import datetime

import httpx

# é è¨­çš„æ¸¬è©¦ JDï¼ˆä¸­æ–‡ï¼‰
DEFAULT_JD = """
Project Manager
Responsible for wafer outsourcing and cost negotiation, including:
Competitive Price: RFQ, price negotiation, cost prediction, cost reduction initiatives, CA.Capacity: long-term reservation, short-term fulfillment, acting as a bridge for internal and external parties to reach goals. Contract: NDA and short-term agreements. Project management (e.g. procurement system)
**Requirement

**Proactive working attitude and good communication skills, with negotiation capability being a plus.Experience in handling wafer sourcing or procurement. Project management and business acumen.

"""

async def test_consistency_kpi(prompt_version: str = "1.4.0", job_description: str = None, num_tests: int = 20):
    """
    åŸ·è¡Œä¸€è‡´æ€§ KPI æ¸¬è©¦ï¼ˆä½¿ç”¨è‡ªå‹•èªè¨€åµæ¸¬ï¼‰
    """
    base_url = "http://localhost:8000/api/v1"
    
    # ä½¿ç”¨æä¾›çš„ JD æˆ–é è¨­å€¼
    jd_to_test = job_description or DEFAULT_JD
    jd_preview = jd_to_test[:100] + "..." if len(jd_to_test) > 100 else jd_to_test
    
    print("ğŸ¯ ä¸€è‡´æ€§ KPI æ¸¬è©¦ï¼ˆè‡ªå‹•èªè¨€åµæ¸¬ç‰ˆï¼‰")
    print("=" * 80)
    print(f"Prompt ç‰ˆæœ¬: {prompt_version}")
    print("èªè¨€è¨­å®š: auto (è‡ªå‹•åµæ¸¬)")
    print(f"æ¸¬è©¦æ¬¡æ•¸: {num_tests}")
    print(f"JD é è¦½: {jd_preview}")
    print("=" * 80)
    
    async with httpx.AsyncClient(timeout=60.0) as client:
        # å„²å­˜æ‰€æœ‰çµæœ
        all_results = []
        successful_runs = 0
        detected_languages = []
        
        print(f"\nğŸ“Š åŸ·è¡Œ {num_tests} æ¬¡æ¸¬è©¦...")
        
        for run in range(num_tests):
            request_data = {
                "job_description": jd_to_test,
                "max_keywords": 16,
                "prompt_version": prompt_version,
                "language": "auto"  # ä½¿ç”¨è‡ªå‹•åµæ¸¬
            }
            
            try:
                response = await client.post(
                    f"{base_url}/extract-jd-keywords",
                    json=request_data
                )
                
                if response.status_code == 200:
                    result = response.json()
                    keywords = result["data"]["keywords"]
                    detected_lang = result["data"].get("detected_language", "unknown")
                    
                    all_results.append(keywords)
                    detected_languages.append(detected_lang)
                    successful_runs += 1
                    
                    print(f"   Run {run+1:2d}: âœ“ ({len(keywords)} keywords, lang={detected_lang})")
                else:
                    print(f"   Run {run+1:2d}: âœ— (Status {response.status_code})")
                    
            except Exception as e:
                print(f"   Run {run+1:2d}: âœ— (Error: {str(e)})")
            
            # å»¶é²é¿å… rate limiting
            await asyncio.sleep(1.5)
        
        # åˆ†æçµæœ
        if successful_runs < 2:
            print("\nâŒ æ¸¬è©¦å¤±æ•—ï¼šæˆåŠŸæ¬¡æ•¸ä¸è¶³")
            return
        
        print(f"\nâœ… æˆåŠŸåŸ·è¡Œ: {successful_runs}/{num_tests} æ¬¡")
        
        # èªè¨€åµæ¸¬çµ±è¨ˆ
        lang_counter = Counter(detected_languages)
        print("\nğŸŒ èªè¨€åµæ¸¬çµ±è¨ˆ:")
        for lang, count in lang_counter.most_common():
            print(f"   {lang}: {count} æ¬¡ ({count/successful_runs*100:.1f}%)")
        
        # é—œéµå­—åˆ†æ
        if all_results:
            # çµ±è¨ˆæ‰€æœ‰é—œéµå­—å‡ºç¾é »ç‡
            keyword_counter = Counter()
            for result in all_results:
                keyword_counter.update(result)
            
            print("\nğŸ“Š é—œéµå­—é »ç‡åˆ†æ:")
            print(f"   ç¸½å…±å‡ºç¾ {len(keyword_counter)} å€‹ä¸åŒé—œéµå­—")
            
            # é¡¯ç¤ºå‰ 20 å€‹æœ€å¸¸å‡ºç¾çš„é—œéµå­—
            print("\nğŸ” å‰ 20 å€‹é«˜é »é—œéµå­—:")
            for i, (keyword, count) in enumerate(keyword_counter.most_common(20), 1):
                percentage = (count / successful_runs) * 100
                print(f"   {i:2d}. {keyword}: {count} æ¬¡ ({percentage:.1f}%)")
            
            # è¨ˆç®—å”¯ä¸€çµ„åˆ
            unique_combinations = {}
            for idx, result in enumerate(all_results):
                # ä½¿ç”¨æ’åºå¾Œçš„é—œéµå­—ä½œç‚ºçµ„åˆçš„æ¨™è­˜
                combo_key = tuple(sorted(result))
                if combo_key not in unique_combinations:
                    unique_combinations[combo_key] = []
                unique_combinations[combo_key].append(idx + 1)
            
            # è¨ˆç®—ä¸€è‡´æ€§å’Œç›¸ä¼¼åº¦
            total_pairs = successful_runs * (successful_runs - 1) // 2
            identical_pairs = 0
            jaccard_scores = []
            
            for i in range(len(all_results)):
                for j in range(i + 1, len(all_results)):
                    set1 = set(all_results[i])
                    set2 = set(all_results[j])
                    
                    # æª¢æŸ¥æ˜¯å¦å®Œå…¨ç›¸åŒ
                    if sorted(all_results[i]) == sorted(all_results[j]):
                        identical_pairs += 1
                    
                    # è¨ˆç®— Jaccard ç›¸ä¼¼åº¦
                    intersection = len(set1 & set2)
                    union = len(set1 | set2)
                    if union > 0:
                        jaccard = intersection / union
                        jaccard_scores.append(jaccard)
            
            consistency_rate = identical_pairs / total_pairs if total_pairs > 0 else 0
            
            print("\nğŸ“Š ä¸€è‡´æ€§ KPI åˆ†æ:")
            print(f"   ç¸½æ¸¬è©¦æ¬¡æ•¸: {successful_runs}")
            print(f"   å”¯ä¸€çµæœçµ„åˆ: {len(unique_combinations)} å€‹")
            
            # é¡¯ç¤ºçµ„åˆåˆ†å¸ƒ
            sorted_combos = sorted(unique_combinations.items(), key=lambda x: len(x[1]), reverse=True)
            print("\n   çµ„åˆåˆ†å¸ƒ:")
            for idx, (combo, occurrences) in enumerate(sorted_combos[:5], 1):
                percentage = (len(occurrences) / successful_runs) * 100
                print(f"   - çµ„åˆ{idx}: {len(occurrences)}æ¬¡ ({percentage:.1f}%)")
            if len(sorted_combos) > 5:
                print(f"   - å…¶ä»–{len(sorted_combos)-5}å€‹çµ„åˆ: å„å‡ºç¾è¼ƒå°‘æ¬¡æ•¸")
            
            print("\n   é…å°çµ±è¨ˆ:")
            print(f"   ç¸½é…å°æ•¸: {total_pairs}")
            print(f"   ç›¸åŒé…å°æ•¸: {identical_pairs}")
            print(f"   å®Œå…¨ä¸€è‡´ç‡: {consistency_rate:.1%}")
            
            # è¨ˆç®— 95% ä¿¡å¿ƒå€é–“
            # ä½¿ç”¨äºŒé …åˆ†ä½ˆçš„æ­£æ…‹è¿‘ä¼¼
            import math
            
            if total_pairs > 0:
                p = consistency_rate
                n = total_pairs
                
                # æ¨™æº–èª¤å·®
                se = math.sqrt(p * (1 - p) / n) if p > 0 and p < 1 else 0
                
                # 95% ä¿¡å¿ƒå€é–“ (z = 1.96)
                z = 1.96
                margin_of_error = z * se
                ci_lower = max(0, p - margin_of_error)
                ci_upper = min(1, p + margin_of_error)
                
                print("\nğŸ“ˆ çµ±è¨ˆåˆ†æ:")
                print(f"   95% ä¿¡å¿ƒå€é–“: [{ci_lower:.1%}, {ci_upper:.1%}]")
                print(f"   æ¨™æº–èª¤å·®: {se:.3f}")
                print(f"   èª¤å·®ç¯„åœ: Â±{margin_of_error:.1%}")
                
                # è§£é‡‹ä¿¡å¿ƒå€é–“
                print("\nğŸ’¡ è§£é‡‹:")
                print("   åœ¨ 95% çš„ä¿¡å¿ƒæ°´æº–ä¸‹ï¼Œä»»å…©æ¬¡åŸ·è¡Œå–å¾—ç›¸åŒé—œéµå­—åˆ—è¡¨çš„æ©Ÿç‡ç‚º:")
                print(f"   {ci_lower:.1%} åˆ° {ci_upper:.1%} ä¹‹é–“")
                
                # è¨ˆç®—é”åˆ°ç›®æ¨™æ‰€éœ€çš„æ¨£æœ¬æ•¸
                target_rate = 0.35
                if consistency_rate < target_rate:
                    # ä½¿ç”¨ç•¶å‰çš„è®Šç•°æ€§ä¼°ç®—éœ€è¦å¤šå°‘æ¬¡æ¸¬è©¦
                    required_identical = math.ceil(target_rate * total_pairs)
                    print("\nğŸ“Š é”æ¨™åˆ†æ:")
                    print(f"   ç›®æ¨™ä¸€è‡´æ€§ç‡: {target_rate:.0%}")
                    print(f"   éœ€è¦ç›¸åŒé…å°æ•¸: {required_identical} (ç›®å‰: {identical_pairs})")
                    print(f"   å·®è·: {required_identical - identical_pairs} å°")
            
            # KPI åˆ¤å®š
            target_rate = 0.35  # 35% ç›®æ¨™å€¼
            if consistency_rate >= target_rate:
                print(f"\nğŸ¯ KPI è©•ä¼°: âœ… é€šéï¼({consistency_rate:.1%} â‰¥ 35%)")
            else:
                print(f"\nğŸ¯ KPI è©•ä¼°: âŒ æœªé”æ¨™ï¼({consistency_rate:.1%} < 35%)")
            
            # Jaccard ç›¸ä¼¼åº¦åˆ†æ
            if jaccard_scores:
                avg_jaccard = sum(jaccard_scores) / len(jaccard_scores)
                min_jaccard = min(jaccard_scores)
                max_jaccard = max(jaccard_scores)
                
                # è¨ˆç®— Jaccard åˆ†æ•¸çš„æ¨™æº–å·®
                jaccard_variance = sum((x - avg_jaccard) ** 2 for x in jaccard_scores) / len(jaccard_scores)
                jaccard_std = math.sqrt(jaccard_variance)
                
                print("\nğŸ“Š Jaccard ç›¸ä¼¼åº¦åˆ†æ:")
                print(f"   å¹³å‡ç›¸ä¼¼åº¦: {avg_jaccard:.1%}")
                print(f"     â†’ ä»»æ„å…©æ¬¡æ¸¬è©¦å¹³å‡æœ‰ {avg_jaccard:.1%} çš„é—œéµå­—é‡ç–Š")
                print(f"     â†’ 16å€‹é—œéµå­—ä¸­ï¼Œå¹³å‡ç´„{int(16 * avg_jaccard)}å€‹æ˜¯ç›¸åŒçš„")
                
                print(f"\n   æœ€ä½ç›¸ä¼¼åº¦: {min_jaccard:.1%}")
                print(f"     â†’ æœ€ä¸ç›¸ä¼¼çš„å…©æ¬¡æ¸¬è©¦ä»æœ‰ {min_jaccard:.1%} é‡ç–Š")
                print(f"     â†’ 16å€‹é—œéµå­—ä¸­ï¼Œè‡³å°‘æœ‰{int(16 * min_jaccard)}å€‹ç›¸åŒ")
                
                print(f"\n   æœ€é«˜ç›¸ä¼¼åº¦: {max_jaccard:.1%}")
                if max_jaccard == 1.0:
                    print("     â†’ æœ‰äº›æ¸¬è©¦å°çš„é—œéµå­—å®Œå…¨ç›¸åŒ")
                else:
                    print(f"     â†’ æœ€ç›¸ä¼¼çš„å…©æ¬¡æ¸¬è©¦æœ‰ {max_jaccard:.1%} é‡ç–Š")
                
                print(f"\n   æ¨™æº–å·®: {jaccard_std:.3f}")
                if jaccard_std < 0.1:
                    print("     â†’ ç›¸ä¼¼åº¦çš„é›¢æ•£ç¨‹åº¦å¾ˆå°ï¼Œè¡¨ç¤ºç©©å®šæ€§é«˜")
                elif jaccard_std < 0.2:
                    print("     â†’ ç›¸ä¼¼åº¦çš„é›¢æ•£ç¨‹åº¦ä¸­ç­‰ï¼Œè¡¨ç¤ºæœ‰ä¸€å®šè®ŠåŒ–")
                else:
                    print("     â†’ ç›¸ä¼¼åº¦çš„é›¢æ•£ç¨‹åº¦è¼ƒå¤§ï¼Œè¡¨ç¤ºè®ŠåŒ–è¼ƒå¤š")
                
                # åˆ†çµ„çµ±è¨ˆ
                high_similarity = sum(1 for s in jaccard_scores if s >= 0.8)
                medium_similarity = sum(1 for s in jaccard_scores if 0.5 <= s < 0.8)
                low_similarity = sum(1 for s in jaccard_scores if s < 0.5)
                
                print("\nğŸ“Š ç›¸ä¼¼åº¦åˆ†å¸ƒ:")
                print(f"   é«˜ç›¸ä¼¼åº¦ (â‰¥80%): {high_similarity} å° ({high_similarity/len(jaccard_scores)*100:.1f}%)")
                print(f"   ä¸­ç›¸ä¼¼åº¦ (50-79%): {medium_similarity} å° ({medium_similarity/len(jaccard_scores)*100:.1f}%)")
                print(f"   ä½ç›¸ä¼¼åº¦ (<50%): {low_similarity} å° ({low_similarity/len(jaccard_scores)*100:.1f}%)")
            
            # å„²å­˜è©³ç´°çµæœåˆ° JSON
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            output_file = f"consistency_test_results_{timestamp}.json"
            
            results = {
                "test_info": {
                    "timestamp": datetime.now().isoformat(),
                    "prompt_version": prompt_version,
                    "language": "auto",
                    "num_tests": num_tests,
                    "successful_runs": successful_runs,
                    "jd_preview": jd_preview
                },
                "consistency_analysis": {
                    "total_pairs": total_pairs,
                    "identical_pairs": identical_pairs,
                    "consistency_rate": consistency_rate,
                    "confidence_interval_95": {
                        "lower": ci_lower if 'ci_lower' in locals() else None,
                        "upper": ci_upper if 'ci_upper' in locals() else None,
                        "margin_of_error": margin_of_error if 'margin_of_error' in locals() else None
                    }
                },
                "jaccard_analysis": {
                    "average": avg_jaccard if jaccard_scores else None,
                    "min": min_jaccard if jaccard_scores else None,
                    "max": max_jaccard if jaccard_scores else None,
                    "std_dev": jaccard_std if jaccard_scores else None,
                    "distribution": {
                        "high": high_similarity if jaccard_scores else 0,
                        "medium": medium_similarity if jaccard_scores else 0,
                        "low": low_similarity if jaccard_scores else 0
                    }
                },
                "keyword_frequency": dict(keyword_counter.most_common()),
                "language_detection": dict(lang_counter),
                "all_results": all_results,
                "kpi_status": "PASSED" if consistency_rate >= target_rate else "FAILED"
            }
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, ensure_ascii=False, indent=2)
            
            print(f"\nğŸ’¾ è©³ç´°çµæœå·²å„²å­˜è‡³: {output_file}")

async def main():
    """ä¸»ç¨‹å¼å…¥å£"""
    # è§£æå‘½ä»¤åˆ—åƒæ•¸
    prompt_version = "1.4.0"  # é è¨­ç‰ˆæœ¬
    job_description = None
    
    if len(sys.argv) > 1:
        prompt_version = sys.argv[1]
    
    if len(sys.argv) > 2:
        # å¾æª”æ¡ˆè®€å– JD
        jd_file = sys.argv[2]
        if jd_file and os.path.exists(jd_file):
            with open(jd_file, encoding='utf-8') as f:
                job_description = f.read()
            print(f"ğŸ“„ å¾æª”æ¡ˆè¼‰å…¥ JD: {jd_file}")
    
    # æª¢æŸ¥ä¼ºæœå™¨æ˜¯å¦é‹è¡Œ
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:8000/api/v1/health")
            if response.status_code != 200:
                print("âŒ API ä¼ºæœå™¨æœªå›æ‡‰")
                return
    except Exception as e:
        print(f"âŒ ç„¡æ³•é€£æ¥åˆ° API ä¼ºæœå™¨: {str(e)}")
        print("\nè«‹å…ˆå•Ÿå‹• API ä¼ºæœå™¨:")
        print("uvicorn src.main:app --reload --port 8000")
        return
    
    # åŸ·è¡Œæ¸¬è©¦
    await test_consistency_kpi(prompt_version, job_description)

if __name__ == "__main__":
    asyncio.run(main())