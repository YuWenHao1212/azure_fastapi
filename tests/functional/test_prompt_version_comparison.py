#!/usr/bin/env python3
"""
å¤šèªè¨€ Prompt ç‰ˆæœ¬æ¯”è¼ƒæ¸¬è©¦
è‡ªå‹•åµæ¸¬èªè¨€ä¸¦æ¯”è¼ƒè©²èªè¨€çš„ä¸åŒ prompt ç‰ˆæœ¬æ•ˆæœ

åŠŸèƒ½:
- è‡ªå‹•åµæ¸¬ JD èªè¨€
- æ¯”è¼ƒè©²èªè¨€å¯ç”¨çš„ prompt ç‰ˆæœ¬ï¼ˆå¦‚ v1.2.0 vs v1.3.0ï¼‰
- åˆ†æå„ç‰ˆæœ¬çš„ä¸€è‡´æ€§å’Œç©©å®šæ€§
- æ‰¾å‡ºæœ€ç©©å®šçš„ç‰ˆæœ¬

ç”¨æ³•:
    python test_prompt_version_comparison.py                    # ä½¿ç”¨é è¨­è‹±æ–‡ JD
    python test_prompt_version_comparison.py --jd-file job.txt  # ä½¿ç”¨æª”æ¡ˆä¸­çš„ JD
    python test_prompt_version_comparison.py --jd "è·ä½æè¿°"     # ç›´æ¥æä¾› JD
    python test_prompt_version_comparison.py --runs 30          # æ¯å€‹ç‰ˆæœ¬æ¸¬è©¦ 30 æ¬¡
"""
import asyncio
import httpx
import argparse
import math
import json
from datetime import datetime
from pathlib import Path
from collections import Counter
from typing import Dict, List, Tuple, Set

# é è¨­è‹±æ–‡æ¸¬è©¦ JD
DEFAULT_ENGLISH_JD = """
Sr. HR Data Analyst

Established in 1987 and headquartered in Taiwan, TSMC pioneered the pure-play foundry business model with an exclusive focus on manufacturing its customersâ€™ products. In 2023, the company served 528 customers with 11,895 products for high performance computing, smartphones, IoT, automotive, and consumer electronics, and is the worldâ€™s largest provider of logic ICs with annual capacity of 16 million 12-inch equivalent wafers. TSMC operates fabs in Taiwan as well as manufacturing subsidiaries in Washington State, Japan and China, and its ESMC subsidiary plans to begin construction on a fab in Germany in 2024. In Arizona, TSMC is building three fabs, with the first starting 4nm production in 2025, the second by 2028, and the third by the end of the decade.

The Sr. HR Data Analyst will be responsible for analyzing large sets of HR data in order to provide insights and recommendations to the HR team and senior management independently or with other HR analysts across global HR team. The role will require a high level of technical expertise in data visualization and analysis, as well as a deep understanding of HR processes and policies.

**Job Responsibilities:**

1. Act as a Tableau data visualization expert and develop strategic HR dashboards with other domain experts in cross-team projects that enables data-informed decisions to stakeholders.
2. Provide guidance, training plans and technical support to other analysts in HR team for Tableau skills development.
3. Translate business needs into technical data requirements and work with IT data platform engineers for data preparation.
4. Create trust and maintain strong relationships with key stakeholders across the organization.
5. Stay up-to-date with industry trends and new analytics features as a technical advocate.

**Job Qualifications:**

1. Master's degree in HR, Business, Statistics, CS or related field.
2. Minimum 5 years of experience in data analysis, with a proven track record of delivering actionable business insights and recommendations.
3. Strong technical skills in data analysis tools such as Tableau, Power BI, Superset and SQL.
4. Excellent communication skills with the ability to effectively communicate complex data insights to non-technical stakeholders.
5. Strong problem-solving skills with the ability to think critically and creatively to solve complex business problems.
6. Ability to work independently and manage multiple projects simultaneously.
7. Strong attention to details and accuracy.
8. Experience in leading and mentoring junior analysts is a plus.
"""

# é è¨­ä¸­æ–‡æ¸¬è©¦ JD
DEFAULT_CHINESE_JD = """
è³‡æ·±è»Ÿé«”å·¥ç¨‹å¸«

æˆ‘å€‘æ­£åœ¨å°‹æ‰¾ä¸€ä½ç¶“é©—è±å¯Œçš„è³‡æ·±è»Ÿé«”å·¥ç¨‹å¸«ï¼ŒåŠ å…¥æˆ‘å€‘çš„æŠ€è¡“åœ˜éšŠã€‚

ä¸»è¦è·è²¬ï¼š
- è¨­è¨ˆå’Œé–‹ç™¼é«˜å“è³ªçš„è»Ÿé«”è§£æ±ºæ–¹æ¡ˆ
- åƒèˆ‡ç³»çµ±æ¶æ§‹è¨­è¨ˆå’ŒæŠ€è¡“æ±ºç­–
- æŒ‡å°åˆç´šå·¥ç¨‹å¸«ä¸¦é€²è¡Œä»£ç¢¼å¯©æŸ¥
- å„ªåŒ–ç³»çµ±æ€§èƒ½å’Œå¯æ“´å±•æ€§
- æ’°å¯«æŠ€è¡“æ–‡æª”å’Œæœ€ä½³å¯¦è¸

æŠ€èƒ½è¦æ±‚ï¼š
- ç²¾é€š Python å’Œç›¸é—œæ¡†æ¶ï¼ˆDjangoã€FastAPIï¼‰
- ç†Ÿæ‚‰å¾®æœå‹™æ¶æ§‹å’Œå®¹å™¨æŠ€è¡“ï¼ˆDockerã€Kubernetesï¼‰
- å…·å‚™è³‡æ–™åº«è¨­è¨ˆå’Œå„ªåŒ–ç¶“é©—ï¼ˆPostgreSQLã€MongoDBï¼‰
- äº†è§£ CI/CD æµç¨‹å’Œ DevOps å¯¦è¸
- è‰¯å¥½çš„å•é¡Œè§£æ±ºèƒ½åŠ›å’Œåœ˜éšŠåˆä½œç²¾ç¥

è³‡æ ¼è¦æ±‚ï¼š
- è¨ˆç®—æ©Ÿç§‘å­¸æˆ–ç›¸é—œé ˜åŸŸå­¸å£«å­¸ä½ä»¥ä¸Š
- 5å¹´ä»¥ä¸Šè»Ÿé«”é–‹ç™¼ç¶“é©—
- å…·å‚™å¤§å‹ç³»çµ±é–‹ç™¼ç¶“é©—è€…å„ªå…ˆ
"""

class PromptVersionComparison:
    """Prompt ç‰ˆæœ¬æ¯”è¼ƒæ¸¬è©¦é¡"""
    
    def __init__(self, runs_per_version: int = 20):
        self.runs_per_version = runs_per_version
        self.base_url = "http://localhost:8000/api/v1"
        self.test_jd = None
        self.detected_language = None
        self.available_versions = []
        
    def set_test_jd(self, jd: str):
        """è¨­å®šæ¸¬è©¦ç”¨çš„ JD"""
        self.test_jd = jd.strip()
    
    async def detect_language_and_versions(self):
        """åµæ¸¬èªè¨€ä¸¦ç²å–å¯ç”¨çš„ prompt ç‰ˆæœ¬"""
        print("\nğŸŒ åµæ¸¬ JD èªè¨€ä¸¦ç²å–å¯ç”¨ç‰ˆæœ¬...")
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            # ç¬¬ä¸€æ¬¡è«‹æ±‚ï¼Œä½¿ç”¨ auto èªè¨€åµæ¸¬
            response = await client.post(
                f"{self.base_url}/extract-jd-keywords",
                json={
                    "job_description": self.test_jd,
                    "max_keywords": 16,
                    "language": "auto"
                }
            )
            
            if response.status_code == 200:
                result = response.json()
                self.detected_language = result["data"].get("detected_language", "unknown")
                current_version = result["data"].get("prompt_version", "latest")
                
                print(f"   åµæ¸¬åˆ°èªè¨€: {self.detected_language}")
                print(f"   ç•¶å‰ä½¿ç”¨ç‰ˆæœ¬: {current_version}")
                
                # æ ¹æ“šèªè¨€æ±ºå®šå¯ç”¨ç‰ˆæœ¬
                if self.detected_language == "en":
                    self.available_versions = ["1.2.0", "1.3.0", "1.4.0"]  # è‹±æ–‡æœ‰ä¸‰å€‹ç‰ˆæœ¬
                elif self.detected_language == "zh-TW":
                    self.available_versions = ["1.2.0", "1.3.0", "1.4.0"]  # ä¸­æ–‡ä¹Ÿæœ‰ä¸‰å€‹ç‰ˆæœ¬
                else:
                    self.available_versions = ["1.3.0"]  # å…¶ä»–èªè¨€åªæœ‰æœ€æ–°ç‰ˆ
                
                print(f"   å¯æ¸¬è©¦ç‰ˆæœ¬: {', '.join(self.available_versions)}")
                
                return True
            else:
                print(f"âŒ èªè¨€åµæ¸¬å¤±æ•—: HTTP {response.status_code}")
                return False
    
    async def test_version_consistency(self, version: str) -> Dict:
        """æ¸¬è©¦ç‰¹å®šç‰ˆæœ¬çš„ä¸€è‡´æ€§"""
        print(f"\nğŸ“‹ æ¸¬è©¦ç‰ˆæœ¬ {version} ({self.runs_per_version} æ¬¡)...")
        
        results = []
        failed_runs = 0
        
        async with httpx.AsyncClient(timeout=60.0) as client:
            for run in range(1, self.runs_per_version + 1):
                try:
                    response = await client.post(
                        f"{self.base_url}/extract-jd-keywords",
                        json={
                            "job_description": self.test_jd,
                            "max_keywords": 16,
                            "prompt_version": version,
                            "language": self.detected_language
                        }
                    )
                    
                    if response.status_code == 200:
                        result = response.json()
                        keywords = result["data"]["keywords"]
                        results.append(keywords)
                        
                        if run <= 5 or run % 5 == 0:
                            print(f"   Run {run:2d}: âœ“ ({len(keywords)} keywords)")
                    else:
                        failed_runs += 1
                        print(f"   Run {run:2d}: âœ— (HTTP {response.status_code})")
                        
                except Exception as e:
                    failed_runs += 1
                    print(f"   Run {run:2d}: âœ— (Error: {str(e)})")
                
                # å»¶é²é¿å… rate limiting
                await asyncio.sleep(1.0)
        
        return {
            "version": version,
            "results": results,
            "failed_runs": failed_runs,
            "success_rate": len(results) / self.runs_per_version
        }
    
    def analyze_consistency(self, version_data: Dict) -> Dict:
        """åˆ†æä¸€å€‹ç‰ˆæœ¬çš„ä¸€è‡´æ€§"""
        results = version_data["results"]
        
        if len(results) < 2:
            return {
                "version": version_data["version"],
                "insufficient_data": True
            }
        
        # è¨ˆç®—å”¯ä¸€çµ„åˆ
        unique_combinations = {}
        for result in results:
            result_tuple = tuple(sorted(result))
            if result_tuple not in unique_combinations:
                unique_combinations[result_tuple] = 0
            unique_combinations[result_tuple] += 1
        
        # è¨ˆç®—é…å°ä¸€è‡´æ€§
        total_pairs = len(results) * (len(results) - 1) // 2
        identical_pairs = 0
        
        for i in range(len(results)):
            for j in range(i + 1, len(results)):
                if sorted(results[i]) == sorted(results[j]):
                    identical_pairs += 1
        
        consistency_rate = identical_pairs / total_pairs if total_pairs > 0 else 0
        
        # è¨ˆç®— 95% ä¿¡å¿ƒå€é–“
        p = consistency_rate
        n = total_pairs
        
        if n > 0 and p > 0 and p < 1:
            se = math.sqrt(p * (1 - p) / n)
            z = 1.96  # 95% ä¿¡å¿ƒæ°´æº–
            ci_lower = max(0, p - z * se)
            ci_upper = min(1, p + z * se)
        else:
            ci_lower = ci_upper = p
        
        # æ‰¾å‡ºæœ€ç©©å®šçš„é—œéµå­—ï¼ˆå‡ºç¾åœ¨æ‰€æœ‰çµæœä¸­ï¼‰
        if results:
            stable_keywords = set(results[0])
            for result in results[1:]:
                stable_keywords &= set(result)
        else:
            stable_keywords = set()
        
        # é—œéµå­—é »ç‡çµ±è¨ˆ
        all_keywords = []
        for result in results:
            all_keywords.extend(result)
        keyword_counter = Counter(all_keywords)
        
        return {
            "version": version_data["version"],
            "success_rate": version_data["success_rate"],
            "unique_combinations": len(unique_combinations),
            "consistency_rate": consistency_rate,
            "confidence_interval": {"lower": ci_lower, "upper": ci_upper},
            "total_pairs": total_pairs,
            "identical_pairs": identical_pairs,
            "stable_keywords": sorted(stable_keywords),
            "stable_keywords_count": len(stable_keywords),
            "top_keywords": keyword_counter.most_common(10),
            "combination_frequencies": sorted(unique_combinations.items(), 
                                            key=lambda x: x[1], reverse=True)[:5]
        }
    
    def compare_versions(self, analyses: List[Dict]) -> Dict:
        """æ¯”è¼ƒä¸åŒç‰ˆæœ¬çš„çµæœ"""
        if len(analyses) < 2:
            return {"insufficient_versions": True}
        
        # æ‰¾å‡ºæœ€ç©©å®šçš„ç‰ˆæœ¬
        best_version = max(analyses, key=lambda x: x["consistency_rate"])
        
        # è¨ˆç®—ç‰ˆæœ¬é–“çš„å…±åŒé—œéµå­—
        version_keywords = {}
        for analysis in analyses:
            if analysis["combination_frequencies"]:
                # ä½¿ç”¨æœ€å¸¸è¦‹çš„çµ„åˆ
                most_common = analysis["combination_frequencies"][0][0]
                version_keywords[analysis["version"]] = set(most_common)
        
        # è¨ˆç®—äº¤é›†
        if len(version_keywords) >= 2:
            versions = list(version_keywords.keys())
            common_keywords = version_keywords[versions[0]]
            for v in versions[1:]:
                common_keywords &= version_keywords[v]
        else:
            common_keywords = set()
        
        return {
            "best_version": best_version["version"],
            "best_consistency": best_version["consistency_rate"],
            "common_keywords_across_versions": sorted(common_keywords),
            "version_comparisons": analyses
        }
    
    async def run_comparison(self):
        """åŸ·è¡Œå®Œæ•´çš„ç‰ˆæœ¬æ¯”è¼ƒæ¸¬è©¦"""
        print(f"\nğŸš€ é–‹å§‹ Prompt ç‰ˆæœ¬æ¯”è¼ƒæ¸¬è©¦")
        print(f"   JD é•·åº¦: {len(self.test_jd)} å­—ç¬¦")
        print(f"   æ¯ç‰ˆæœ¬æ¸¬è©¦æ¬¡æ•¸: {self.runs_per_version}")
        print("=" * 80)
        
        # åµæ¸¬èªè¨€å’Œç‰ˆæœ¬
        if not await self.detect_language_and_versions():
            return
        
        if len(self.available_versions) < 2:
            print(f"\nâš ï¸  {self.detected_language} èªè¨€åªæœ‰ä¸€å€‹ç‰ˆæœ¬å¯ç”¨ï¼Œç„¡æ³•é€²è¡Œæ¯”è¼ƒ")
            return
        
        # æ¸¬è©¦æ¯å€‹ç‰ˆæœ¬
        version_results = []
        for version in self.available_versions:
            result = await self.test_version_consistency(version)
            version_results.append(result)
        
        # åˆ†æçµæœ
        print("\n\nğŸ“Š ä¸€è‡´æ€§åˆ†æçµæœ")
        print("=" * 80)
        
        analyses = []
        for version_data in version_results:
            analysis = self.analyze_consistency(version_data)
            analyses.append(analysis)
            
            print(f"\nğŸ” ç‰ˆæœ¬ {analysis['version']}")
            print(f"   æˆåŠŸç‡: {analysis['success_rate']:.1%}")
            print(f"   å”¯ä¸€çµ„åˆæ•¸: {analysis['unique_combinations']}")
            print(f"   ä¸€è‡´æ€§ç‡: {analysis['consistency_rate']:.1%}")
            print(f"   95% ä¿¡å¿ƒå€é–“: [{analysis['confidence_interval']['lower']:.1%}, "
                  f"{analysis['confidence_interval']['upper']:.1%}]")
            print(f"   100% ç©©å®šé—œéµå­—æ•¸: {analysis['stable_keywords_count']}")
            
            # é¡¯ç¤ºçµ„åˆé »ç‡
            print("\n   çµ„åˆé »ç‡ (å‰5):")
            for i, (combo, count) in enumerate(analysis['combination_frequencies'][:5]):
                percentage = (count / len(version_data['results'])) * 100
                print(f"     çµ„åˆ {i+1}: {count} æ¬¡ ({percentage:.1f}%)")
                if i == 0:  # é¡¯ç¤ºæœ€å¸¸è¦‹çµ„åˆçš„å‰10å€‹é—œéµå­—
                    print(f"       é—œéµå­—: {', '.join(sorted(combo)[:10])}...")
        
        # ç‰ˆæœ¬æ¯”è¼ƒ
        comparison = self.compare_versions(analyses)
        
        print("\n\nğŸ”„ ç‰ˆæœ¬æ¯”è¼ƒç¸½çµ")
        print("=" * 80)
        print(f"   æœ€ç©©å®šç‰ˆæœ¬: {comparison['best_version']} "
              f"(ä¸€è‡´æ€§ {comparison['best_consistency']:.1%})")
        print(f"   è·¨ç‰ˆæœ¬å…±åŒé—œéµå­—æ•¸: {len(comparison['common_keywords_across_versions'])}")
        
        if comparison['common_keywords_across_versions']:
            print(f"   å…±åŒé—œéµå­—: {', '.join(comparison['common_keywords_across_versions'][:10])}...")
        
        # ç”Ÿæˆå ±å‘Š
        self.generate_report(analyses, comparison)
    
    def generate_report(self, analyses: List[Dict], comparison: Dict):
        """ç”Ÿæˆè©³ç´°å ±å‘Š"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"prompt_version_comparison_{self.detected_language}_{timestamp}.json"
        
        report_data = {
            "test_info": {
                "timestamp": datetime.now().isoformat(),
                "detected_language": self.detected_language,
                "available_versions": self.available_versions,
                "runs_per_version": self.runs_per_version,
                "jd_length": len(self.test_jd),
                "jd_preview": self.test_jd[:200] + "..." if len(self.test_jd) > 200 else self.test_jd
            },
            "version_analyses": analyses,
            "comparison_summary": comparison,
            "recommendations": {
                "best_version": comparison['best_version'],
                "reason": f"æœ€é«˜ä¸€è‡´æ€§ {comparison['best_consistency']:.1%}"
            }
        }
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report_data, f, ensure_ascii=False, indent=2)
        
        print(f"\n\nğŸ“„ è©³ç´°å ±å‘Šå·²ä¿å­˜: {report_file}")


def parse_arguments():
    """è§£æå‘½ä»¤åˆ—åƒæ•¸"""
    parser = argparse.ArgumentParser(
        description="å¤šèªè¨€ Prompt ç‰ˆæœ¬æ¯”è¼ƒæ¸¬è©¦",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¯„ä¾‹:
  %(prog)s                           # ä½¿ç”¨é è¨­è‹±æ–‡ JD
  %(prog)s --jd-file chinese.txt    # ä½¿ç”¨æª”æ¡ˆä¸­çš„ JD
  %(prog)s --jd "è·ä½æè¿°å…§å®¹"        # ç›´æ¥æä¾› JD å…§å®¹
  %(prog)s --runs 30                # æ¯å€‹ç‰ˆæœ¬æ¸¬è©¦ 30 æ¬¡
  %(prog)s --chinese                # ä½¿ç”¨é è¨­ä¸­æ–‡ JD
        """
    )
    
    # JD ä¾†æº
    jd_group = parser.add_mutually_exclusive_group()
    jd_group.add_argument(
        '--jd-file', 
        type=str,
        help='å¾æª”æ¡ˆè®€å– JD å…§å®¹'
    )
    jd_group.add_argument(
        '--jd',
        type=str,
        help='ç›´æ¥æä¾› JD å…§å®¹'
    )
    jd_group.add_argument(
        '--chinese',
        action='store_true',
        help='ä½¿ç”¨é è¨­ä¸­æ–‡ JD'
    )
    
    # æ¸¬è©¦æ¬¡æ•¸
    parser.add_argument(
        '-r', '--runs',
        type=int,
        default=20,
        help='æ¯å€‹ç‰ˆæœ¬çš„æ¸¬è©¦æ¬¡æ•¸ï¼ˆé è¨­: 20ï¼‰'
    )
    
    return parser.parse_args()


async def main():
    """ä¸»å‡½æ•¸"""
    args = parse_arguments()
    
    # æª¢æŸ¥ä¼ºæœå™¨æ˜¯å¦é‹è¡Œ
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get("http://localhost:8000/api/v1/health")
            if response.status_code != 200:
                print("âŒ API ä¼ºæœå™¨æœªå›æ‡‰")
                return
    except Exception:
        print("âŒ ç„¡æ³•é€£æ¥åˆ° API ä¼ºæœå™¨")
        print("è«‹å…ˆå•Ÿå‹•ä¼ºæœå™¨: uvicorn src.main:app --reload")
        return
    
    # æ±ºå®šä½¿ç”¨çš„ JD
    if args.jd_file:
        try:
            with open(args.jd_file, 'r', encoding='utf-8') as f:
                test_jd = f.read()
            print(f"ğŸ“„ å¾æª”æ¡ˆè¼‰å…¥ JD: {args.jd_file}")
        except Exception as e:
            print(f"âŒ ç„¡æ³•è®€å–æª”æ¡ˆ: {e}")
            return
    elif args.jd:
        test_jd = args.jd
        print("ğŸ“ ä½¿ç”¨å‘½ä»¤åˆ—æä¾›çš„ JD")
    elif args.chinese:
        test_jd = DEFAULT_CHINESE_JD
        print("ğŸ“ ä½¿ç”¨é è¨­ä¸­æ–‡ JD")
    else:
        test_jd = DEFAULT_ENGLISH_JD
        print("ğŸ“ ä½¿ç”¨é è¨­è‹±æ–‡ JD")
    
    # åŸ·è¡Œæ¸¬è©¦
    tester = PromptVersionComparison(runs_per_version=args.runs)
    tester.set_test_jd(test_jd)
    await tester.run_comparison()
    
    print("\nâœ… æ¸¬è©¦å®Œæˆï¼")


if __name__ == "__main__":
    asyncio.run(main())